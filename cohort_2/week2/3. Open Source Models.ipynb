{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running the notebook in colab, make sure that you run the following cell. \n",
    "\n",
    "**There is no need to do so if you're cloning the repository locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!curl -L -o ./data/categories.json https://raw.githubusercontent.com/567-labs/systematically-improving-rag/main/cohort_2/week2/data/categories.json\n",
    "!curl -L -o ./data/cleaned.jsonl https://raw.githubusercontent.com/567-labs/systematically-improving-rag/main/cohort_2/week2/data/cleaned.jsonl\n",
    "!curl -L -o ./data/eval_transactions.jsonl https://raw.githubusercontent.com/567-labs/systematically-improving-rag/main/cohort_2/week2/data/eval_transactions.jsonl\n",
    "!curl -L -o ./data/train_transactions.jsonl https://raw.githubusercontent.com/567-labs/systematically-improving-rag/main/cohort_2/week2/data/train_transactions.jsonl\n",
    "!curl -L -o ./helpers.py https://raw.githubusercontent.com/567-labs/systematically-improving-rag/main/cohort_2/week2/helpers.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
    "os.environ[\"BRAINTRUST_API_KEY\"] = userdata.get(\"BRAINTRUST_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers===3.1.1 transformers==4.45.2 braintrust lancedb datasets\n",
    "!pip uninstall wandb -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 : Fine-tuning Open Source Embedding Models\n",
    "\n",
    "> **Prerequisites** : Before running this notebook, make sure that you've completed the previous two notebooks in this week - [1. Synthetic Transactions.ipynb](1. Synthetic Transactions.ipynb) and [2. Finetune Cohere.ipynb](2. Finetune Cohere.ipynb). This notebook will build on top of the previous two notebooks.\n",
    "> \n",
    "> You must have a hugging face token with write access set as an environment variable. If you don't have one, you can create one by following the instructions [here](https://huggingface.co/docs/hub/en/security-tokens).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/567-labs/systematically-improving-rag/blob/main/cohort_2/week2/3.%20Open%20Source%20Models.ipynb)\n",
    "\n",
    "\n",
    "After exploring managed services, let's dive into fine-tuning open source embedding models. While this approach requires more setup, it offers greater control and potential cost savings.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Fine-tuning open source models gives you full control over how your model learns and behaves. While we'll use a small synthetic dataset of 256 examples for this tutorial, real-world applications benefit greatly from larger private datasets - the larger the better. This is because larger datasets allow you to capture specific domain knowledge and relationships that general models might miss.\n",
    "\n",
    "The main advantage of open source fine-tuning is the cost savings at inference time. Once trained, you can run these models on your own infrastructure without paying per-query fees. This makes them especially attractive for high-volume applications. We'll use sentence-transformers since it offers robust training options, works seamlessly with popular model hubs, and has strong community support.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "Though this hands on tutorial, you learn how to\n",
    "\n",
    "This notebook walks through:\n",
    "\n",
    "1. **Dataset Preparation**\n",
    "   - Creating train/test/eval splits\n",
    "   - Formatting data for triplet loss\n",
    "   - Setting up evaluation metrics\n",
    "\n",
    "2. **Model Fine-tuning**\n",
    "   - Configuring training arguments\n",
    "   - Setting up loss functions\n",
    "   - Training and monitoring progress\n",
    "   \n",
    "3. **Performance Evaluation**\n",
    "   - Comparing against base model\n",
    "   - Measuring recall and MRR improvements\n",
    "   - Analyzing trade-offs\n",
    "\n",
    "\n",
    "By the end of this notebook, you'll have a better understanding of when you might want to consider fine-tuning an open source embedding model, how you can do so using the `sentence-transformers` library and how to evaluate the performance of your fine-tuned model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this section, we'll be fine-tuning the `BAAI/bge-base-en` model. We'll be using the `BatchSemiHardTripletLoss` loss function to train our model. Let's first understand how this loss function works before we dive into the code\n",
    "\n",
    "### Understanding Semi-Hard Triplet Loss\n",
    "\n",
    "\n",
    "A Batch Semi Hard Triplet Loss works by taking a batch of sentence pairs and computing the loss for all possible valid triplets, then identifying semi-hard positives and negatives. A semi-hard negative is an example that is not as close to the anchor as the positive example, but is still close to the anchor than the negative example. \n",
    "It works with three pieces:\n",
    "\n",
    "1. An anchor (your main example) - in our case, a transaction description\n",
    "2. A positive match (something similar) - the correct category\n",
    "3. A negative match (something different) - incorrect categories that are close, but not quite right\n",
    "\n",
    "We can see an example of this in the image below where we have an achor, a positive match and a negative match. The negative match is not as close to the anchor as the positive match, but is still close to the anchor than the negative match.\n",
    "\n",
    "<img src=\"./data/hard_negatives.png\" width=\"500\" alt=\"Semi-hard negative mining illustration\"/>\n",
    "\n",
    "For our transaction data, this translates to:\n",
    "- Anchor: Transaction description\n",
    "- Positive: Correct category\n",
    "- Negative: Similar but incorrect categories\n",
    "\n",
    "It's important here to note that the reason why we want an example that's **semi-hard** is because we want to find negative examples that are tricky. They need to be different as compared to the anchor, but not too different. This ultimately helps the model learn to distinguish between similar and dissimilar examples.\n",
    "\n",
    "\n",
    "<img src = \"./data/semi-hard-negative.png\" width = 500 />\n",
    "\n",
    "Using our Cohere dataset format:\n",
    "\n",
    "1. The transaction description becomes our anchor (query)\n",
    "2. The correct category is our positive match (relevant_passages)\n",
    "3. Similar but wrong categories are our negative matches (hard_negatives)\n",
    "\n",
    "While a single training run can provide a baseline, exploring hyperparameter optimization—through techniques like grid or random search—can significantly enhance model performance, especially when executed on a larger scale with appropriate computational resources. Here's a quick example of [how we can do this using `modal` to run a grid search over all possible parameters](https://modal.com/blog/fine-tuning-embeddings)\n",
    "\n",
    "\n",
    "### Declaring Constants\n",
    "\n",
    "When writing fine-tuning code, we want to declare our constants up front. This ensures that we have a consistent set of parameters to use when training our model and makes it easy for us to change them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve the warning from huggingface/tokenizers about parallelism:\n",
    "# 1. Avoid using `tokenizers` before the fork if possible.\n",
    "# 2. Explicitly set the environment variable TOKENIZERS_PARALLELISM to either 'true' or 'false'.\n",
    "import os\n",
    "\n",
    "# Set the environment variable to disable parallelism warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "BASE_MODEL_NAME = \"BAAI/bge-base-en\"\n",
    "FINETUNED_MODEL_NAME = \"ivanleomk/finetuned-bge-base-en\"\n",
    "\n",
    "MODEL_OUTPUT_DIR = \"./models/bge-base-en\"\n",
    "CATEGORIES_PATH = \"data/categories.json\"\n",
    "TRAIN_EVALUATOR_NAME = \"bge-base-en-train\"\n",
    "EVAL_EVALUATOR_NAME = \"bge-base-en-eval\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Dataset\n",
    "\n",
    "While we use the same dataset as before, we need to handle a lot more configuration when fine-tuning open source models in order for us to evaluate our model's performance while training as well as to use the `BatchSemiHardTripletLoss` loss function.\n",
    "\n",
    "To do so, we'll format our original train and eval split into a train, test and eval split. \n",
    "\n",
    "- Train : This is only used to train the model\n",
    "- Test : This is used to evaluate the model during training\n",
    "- Eval : This is used to evaluate the model after training\n",
    "\n",
    "We want to have a separate set of data points set aside for testing our model during training or to use when evaluating different versions of our model. This ensures that our model does not overfit to the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanleo/Documents/coding/systematically-improving-rag/cohort_2/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from helpers import get_dataset_split\n",
    "categories = json.load(open(CATEGORIES_PATH))\n",
    "\n",
    "\n",
    "train_data = get_dataset_split(\"./data/train_transactions.jsonl\")\n",
    "eval_data = get_dataset_split(\"./data/eval_transactions.jsonl\")\n",
    "test_data = train_data[: int(len(train_data) * TEST_SIZE)]\n",
    "train_data = train_data[int(len(train_data) * TEST_SIZE) :]\n",
    "len(test_data),len(train_data),len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def create_labels(data):\n",
    "    label_to_example = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        label_to_example[item[\"expected\"][0]].append(item)\n",
    "\n",
    "    return {label: idx for idx, label in enumerate(label_to_example.keys())}\n",
    "\n",
    "\n",
    "def create_sentence_to_label_dataset(data, label_to_idx):\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"sentence\": [item[\"input\"] for item in data],\n",
    "            \"label\": [label_to_idx[item[\"expected\"][0]] for item in data],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def create_triplet_dataset(data):\n",
    "    label_to_example = defaultdict(list)\n",
    "\n",
    "    for item in data:\n",
    "        label_to_example[item[\"expected\"][0]].append(item)\n",
    "\n",
    "    labels = set(label_to_example.keys())\n",
    "\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    negatives = []\n",
    "\n",
    "    for item in data:\n",
    "        label = item[\"expected\"][0]\n",
    "        anchor = item\n",
    "        positive = label\n",
    "        negative = random.choice([item for item in labels if item != label])\n",
    "        anchors.append(anchor)\n",
    "        positives.append(positive)\n",
    "        negatives.append(negative)\n",
    "\n",
    "    return {\"anchor\": anchors, \"positive\": positives, \"negative\": negatives}\n",
    "\n",
    "\n",
    "labels_to_idx = create_labels(train_data)\n",
    "\n",
    "train_triplets = create_triplet_dataset(train_data)\n",
    "test_triplets = create_triplet_dataset(test_data)\n",
    "eval_triplets = create_triplet_dataset(eval_data)\n",
    "\n",
    "sentence_to_label_train_dataset = create_sentence_to_label_dataset(\n",
    "    train_data, labels_to_idx\n",
    ")\n",
    "sentence_to_label_test_dataset = create_sentence_to_label_dataset(\n",
    "    test_data, labels_to_idx\n",
    ")\n",
    "sentence_to_label_eval_dataset = create_sentence_to_label_dataset(\n",
    "    eval_data, labels_to_idx\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "\n",
    "Now that we have our training data formatted in the right format, we can start training our model. We'll do so in 3 steps\n",
    "\n",
    "1. First we'll declare training arguments - we're using the default arguments provided in their documentation but ideally you'd want to experiment and tinkker with different configurations\n",
    "\n",
    "2. Next we'll start a training run. We're using the `wandb` integration here to log our training run to Weights & Biases. You'll need to create a Weights & Biases account and authenticate with `wandb login`\n",
    "\n",
    "3. Finally, we'll train our model before uploading it to the Hugging Face model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bge-base-en-train_cosine_accuracy': 0.8269230769230769,\n",
       " 'bge-base-en-train_dot_accuracy': 0.17307692307692307,\n",
       " 'bge-base-en-train_manhattan_accuracy': 0.8173076923076923,\n",
       " 'bge-base-en-train_euclidean_accuracy': 0.8269230769230769,\n",
       " 'bge-base-en-train_max_accuracy': 0.8269230769230769}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "from sentence_transformers.losses import BatchSemiHardTripletLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "\n",
    "model = SentenceTransformer(BASE_MODEL_NAME)\n",
    "loss = BatchSemiHardTripletLoss(model)\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required parameter:\n",
    "    output_dir=MODEL_OUTPUT_DIR,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=False,  # Set to False if you get an error that your GPU can't run on FP16\n",
    "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "train_evaluator = TripletEvaluator(\n",
    "    anchors=train_triplets[\"anchor\"],\n",
    "    positives=train_triplets[\"positive\"],\n",
    "    negatives=train_triplets[\"negative\"],\n",
    "    name=TRAIN_EVALUATOR_NAME,\n",
    ")\n",
    "\n",
    "train_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78726d19657542eeac9b27605eecf183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c6fdcb18247aeb5ff7b310a0c6e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7.9645, 'train_samples_per_second': 130.58, 'train_steps_per_second': 8.161, 'train_loss': 4.90084463266226, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=65, training_loss=4.90084463266226, metrics={'train_runtime': 7.9645, 'train_samples_per_second': 130.58, 'train_steps_per_second': 8.161, 'total_flos': 0.0, 'train_loss': 4.90084463266226, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=sentence_to_label_train_dataset,\n",
    "    eval_dataset=sentence_to_label_test_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=train_evaluator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bge-base-en-eval_cosine_accuracy': 0.9393939393939394,\n",
       " 'bge-base-en-eval_dot_accuracy': 0.06060606060606061,\n",
       " 'bge-base-en-eval_manhattan_accuracy': 0.9393939393939394,\n",
       " 'bge-base-en-eval_euclidean_accuracy': 0.9393939393939394,\n",
       " 'bge-base-en-eval_max_accuracy': 0.9393939393939394}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator = TripletEvaluator(\n",
    "    anchors=eval_triplets[\"anchor\"],\n",
    "    positives=eval_triplets[\"positive\"],\n",
    "    negatives=eval_triplets[\"negative\"],\n",
    "    name=EVAL_EVALUATOR_NAME,\n",
    ")\n",
    "test_evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e9ba978cf6423fb52d1aa5f3c08501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/ivanleomk/finetuned-bge-base-en/commit/3abaa388fc4aa26f87d831b3ea787703a1681ca6'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"models/finetuned-{BASE_MODEL_NAME}\")\n",
    "model.push_to_hub(FINETUNED_MODEL_NAME, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "> **Note** : If you haven't had your braintrust free tier bumped yet, we've implemented a version below that uses the ThreadPoolExecutor to parallelize the evaluation process instead. Scroll down a bit more to see it.\n",
    "\n",
    "Here we use `lancedb` again to evaluate our model. It comes with out of the box support for hugging face models, which makkes it incredibly easy for us to evaluate our fine-tuned model vs the base model. \n",
    "\n",
    "We'll similarly use `braintrust` to evaluate our model and compare it against the base model by looking at recall and mrr @1,3,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "import json\n",
    "\n",
    "def create_lancedb_table(model_name: str, categories: list[str]):\n",
    "    model = get_registry().get(\"huggingface\").create(name=model_name)\n",
    "\n",
    "\n",
    "    class Category(LanceModel):\n",
    "        text: str = model.SourceField()\n",
    "        embedding: Vector(model.ndims()) = model.VectorField()\n",
    "\n",
    "\n",
    "    db = lancedb.connect(\"./lancedb\")\n",
    "    table_name = f\"categories-{model_name.replace('/', '-')}\"\n",
    "    if table_name in db.table_names():\n",
    "        table = db.open_table(table_name)\n",
    "    else:\n",
    "        table = db.create_table(\n",
    "            table_name, schema=Category, mode=\"overwrite\"\n",
    "        )\n",
    "        table.add(\n",
    "            [\n",
    "                {\n",
    "                    \"text\": category[\"category\"],\n",
    "                }\n",
    "                for category in categories\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment synthetic-transactions-train-categories-BAAI-bge-base-en-0e21f37e is running at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-BAAI-bge-base-en-0e21f37e\n",
      "fine-tuning [experiment_name=synthetic-transactions-train-categories-BAAI-bge-base-en] (data): 66it [00:00, 7679.96it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1fbb94f68448c8b11f0b1d35041368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fine-tuning [experiment_name=synthetic-transactions-train-categories-BAAI-bge-base-en] (tasks):   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "synthetic-transactions-train-categories-BAAI-bge-base-en-0e21f37e compared to synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-test:\n",
      "39.39% (-18.18%) 'mrr@1'    score\t(5 improvements, 17 regressions)\n",
      "53.28% (-17.93%) 'mrr@3'    score\t(6 improvements, 26 regressions)\n",
      "54.27% (-18.31%) 'mrr@5'    score\t(6 improvements, 29 regressions)\n",
      "39.39% (-18.18%) 'recall@1' score\t(5 improvements, 17 regressions)\n",
      "71.21% (-15.15%) 'recall@3' score\t(1 improvements, 11 regressions)\n",
      "75.76% (-16.67%) 'recall@5' score\t(0 improvements, 11 regressions)\n",
      "\n",
      "1739747903.70s start\n",
      "1739747904.89s end\n",
      "0.85s (-46.46%) 'duration'\t(66 improvements, 0 regressions)\n",
      "\n",
      "See results for synthetic-transactions-train-categories-BAAI-bge-base-en-0e21f37e at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-BAAI-bge-base-en-0e21f37e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-0d7d8650 is running at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-0d7d8650\n",
      "fine-tuning [experiment_name=synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en] (data): 66it [00:00, 43396.15it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4f12fe897e41c1af7f4811c280cc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fine-tuning [experiment_name=synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en] (tasks):…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================SUMMARY=========================\n",
      "synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-0d7d8650 compared to synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-test:\n",
      "54.55% (-03.03%) 'mrr@1'    score\t(1 improvements, 3 regressions)\n",
      "69.44% (-01.77%) 'mrr@3'    score\t(2 improvements, 5 regressions)\n",
      "70.20% (-02.37%) 'mrr@5'    score\t(2 improvements, 7 regressions)\n",
      "54.55% (-03.03%) 'recall@1' score\t(1 improvements, 3 regressions)\n",
      "86.36% (-) 'recall@3' score\t(0 improvements, 0 regressions)\n",
      "89.39% (-03.03%) 'recall@5' score\t(0 improvements, 2 regressions)\n",
      "\n",
      "1739747908.17s start\n",
      "1739747911.53s end\n",
      "3.03s (+170.91%) 'duration'\t(0 improvements, 66 regressions)\n",
      "\n",
      "See results for synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-0d7d8650 at https://www.braintrust.dev/app/567/p/fine-tuning/experiments/synthetic-transactions-train-categories-ivanleomk-finetuned-bge-base-en-0d7d8650\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from braintrust import Score, EvalAsync\n",
    "from helpers import get_metrics_at_k, task\n",
    "import json\n",
    "\n",
    "categories = json.load(open(CATEGORIES_PATH))\n",
    "base_table = create_lancedb_table(BASE_MODEL_NAME, categories)\n",
    "finetuned_table = create_lancedb_table(FINETUNED_MODEL_NAME, categories)\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "\n",
    "\n",
    "def evaluate_braintrust(input, output, **kwargs):\n",
    "    metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5])\n",
    "    return [\n",
    "        Score(\n",
    "            name=metric,\n",
    "            score=score_fn(output, kwargs[\"expected\"]),\n",
    "            metadata={\"query\": input, \"result\": output, **kwargs[\"metadata\"]},\n",
    "        )\n",
    "        for metric, score_fn in metrics.items()\n",
    "    ]\n",
    "\n",
    "results = []\n",
    "for query_table in [base_table, finetuned_table]:\n",
    "    results.append(\n",
    "        await EvalAsync(\n",
    "        \"fine-tuning\",\n",
    "        experiment_name=f\"synthetic-transactions-train-{query_table.name}\",\n",
    "        data=lambda: eval_data,\n",
    "        task=lambda query: task(user_query=query, table=query_table, reranker=None, max_k=25),\n",
    "        scores=[evaluate_braintrust],\n",
    "        metadata={\"model\": query_table.name},\n",
    "    )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrr@1</th>\n",
       "      <th>mrr@3</th>\n",
       "      <th>mrr@5</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-Tuned Model</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mrr@1  mrr@3  mrr@5  recall@1  recall@3  recall@5\n",
       "Base Model         0.39   0.53   0.54      0.39      0.71      0.76\n",
       "Fine-Tuned Model   0.55   0.69   0.70      0.55      0.86      0.89"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores = []\n",
    "\n",
    "for result in results:\n",
    "    result_scores = {}\n",
    "    for score_name, score in result.summary.scores.items():\n",
    "        result_scores[score_name] = score.score\n",
    "    scores.append(result_scores)\n",
    "\n",
    "df = pd.DataFrame(scores,index=[\"Base Model\", \"Fine-Tuned Model\"])\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr@1       0.3939\n",
      "mrr@3       0.5328\n",
      "mrr@5       0.5427\n",
      "recall@1    0.3939\n",
      "recall@3    0.7121\n",
      "recall@5    0.7576\n",
      "dtype: float64\n",
      "mrr@1       0.5455\n",
      "mrr@3       0.6944\n",
      "mrr@5       0.7020\n",
      "recall@1    0.5455\n",
      "recall@3    0.8636\n",
      "recall@5    0.8939\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from helpers import task, get_metrics_at_k\n",
    "import pandas as pd\n",
    "\n",
    "metrics = get_metrics_at_k(metrics=[\"mrr\", \"recall\"], sizes=[1, 3, 5])\n",
    "\n",
    "def evaluate_query(output, expense_category):\n",
    "    scores = {}\n",
    "    for metric, score_fn in metrics.items():\n",
    "        scores[metric] = score_fn(output, expense_category)\n",
    "    return scores\n",
    "\n",
    "results = {}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    for table in [base_table, finetuned_table]:\n",
    "        query_results = list(\n",
    "            executor.map(\n",
    "                lambda q: task(\n",
    "                    user_query=q[\"input\"], \n",
    "                    table=table,\n",
    "                    reranker=None,\n",
    "                    max_k=25\n",
    "                ),\n",
    "                eval_data,\n",
    "            )\n",
    "        )\n",
    "        scores = [\n",
    "            evaluate_query(output, transaction[\"expected\"]) \n",
    "            for output, transaction in zip(query_results, eval_data)\n",
    "        ]\n",
    "        df = pd.DataFrame(scores)\n",
    "        results[table.name] = round(pd.DataFrame(scores).mean(), 4)\n",
    "        print(results[table.name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrr@1</th>\n",
       "      <th>mrr@3</th>\n",
       "      <th>mrr@5</th>\n",
       "      <th>recall@1</th>\n",
       "      <th>recall@3</th>\n",
       "      <th>recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Model</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fine-Tuned Model</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mrr@1  mrr@3  mrr@5  recall@1  recall@3  recall@5\n",
       "Base Model         0.39   0.53   0.54      0.39      0.71      0.76\n",
       "Fine-Tuned Model   0.55   0.69   0.70      0.55      0.86      0.89"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(results.values(), index=[\"Base Model\", \"Fine-Tuned Model\"])\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Plot MRR scores\n",
    "mrr_cols = ['mrr@1', 'mrr@3', 'mrr@5']\n",
    "x = np.arange(len(mrr_cols))\n",
    "width = 0.25\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    offset = (i - 1) * width\n",
    "    ax1.bar(x + offset, df.loc[model, mrr_cols], width, label=model)\n",
    "\n",
    "ax1.set_title('Mean Reciprocal Rank (MRR)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(mrr_cols)\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot Recall scores\n",
    "recall_cols = ['recall@1', 'recall@3', 'recall@5']\n",
    "x = np.arange(len(recall_cols))\n",
    "\n",
    "for i, model in enumerate(df.index):\n",
    "    offset = (i - 1) * width\n",
    "    ax2.bar(x + offset, df.loc[model, recall_cols], width, label=model)\n",
    "\n",
    "ax2.set_title('Recall')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(recall_cols)\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we successfully fine-tuned the BAAI/bge-base-en model using sentence-transformers, achieving a 20% improvement in MRR@1 and a 12% increase in recall@5 compared to the base model. More importantly, we learned how to balance performance gains against implementation complexity.\n",
    "\n",
    "This concludes our exploration of fine-tuning approaches, where we:\n",
    "\n",
    "1. Created synthetic training data thoughtfully using iterative generation and manual review to ensure quality\n",
    "2. Explored managed re-rankers through Cohere, showing how they offer quick wins with minimal setup\n",
    "3. Implemented open-source fine-tuning using sentence-transformers, trading simplicity for greater control and lower inference costs\n",
    "\n",
    "While managed solutions like Cohere offer faster time-to-production and simplified deployment, open-source models provide greater control and customization potential. The choice between these approaches should be guided by your specific requirements, resources, and the level of performance improvement needed for your use case. \n",
    "\n",
    "These retrieval improvements complement the techniques we'll explore in later weeks - like discovering query patterns (Week 4) and handling structured data (Week 5). By combining effective retrieval with these methods, we can build more robust and capable RAG systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
