{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Conversations: Discovering User Query Patterns\n",
        "\n",
        "> **Series Overview**: This is the first notebook in a three-part series on systematically analyzing and improving RAG systems. We'll move from raw user queries to production-ready classifiers that enable data-driven improvements.\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "In large-scale RAG applications, you'll encounter thousands of user queries. Manually reviewing each is impossible, and simple keyword counting misses deeper patterns. **Topic modeling helps you systematically identify patterns in user queries**, giving you insights into what users are asking and how well your system serves them.\n",
        "\n",
        "Topic modeling serves as the foundation for transforming raw user interactions into actionable insights by:\n",
        "\n",
        "1. **Revealing clusters** of similar queries that might need specialized handling\n",
        "2. **Providing evidence** for prioritizing improvements based on actual usage patterns\n",
        "3. **Highlighting gaps** where your retrieval might be underperforming\n",
        "4. **Creating a foundation** for building automated classification systems\n",
        "\n",
        "While topic modeling isn't objective ground truth, it's an invaluable discovery tool that helps you understand where to focus limited engineering resources based on real user behavior rather than intuition.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this first notebook, you'll discover how to:\n",
        "\n",
        "1. **Prepare Query Data for Analysis**\n",
        "   - Format JSON data into Kura conversation objects\n",
        "   - Structure query-document pairs with proper metadata\n",
        "   - Set up data for effective clustering\n",
        "\n",
        "2. **Run Hierarchical Topic Clustering**\n",
        "   - Use Kura's procedural API for LLM-enhanced clustering\n",
        "   - Generate meaningful summaries of conversation groups\n",
        "   - Visualize the topic hierarchies that emerge\n",
        "\n",
        "3. **Analyze and Interpret Results**\n",
        "   - Examine cluster themes and distribution patterns\n",
        "   - Identify high-impact areas for system improvements\n",
        "   - Recognize limitations in default summarization\n",
        "\n",
        "## What You'll Discover\n",
        "\n",
        "**By the end of this notebook, you'll uncover that just three major topics account for over two-thirds of all user queries**, with artifact management appearing as a dominant theme across 61% of conversations. However, you'll also discover that default summaries are too generic, missing crucial details about specific W&B features—a limitation that motivates the custom summarization approach in the next notebook.\n",
        "\n",
        "## What Makes Kura Different\n",
        "\n",
        "Traditional topic modeling approaches like BERTopic or LDA rely purely on embeddings to group similar documents. **Kura enhances this process by leveraging LLMs to**:\n",
        "\n",
        "1. **Generate Meaningful Summaries** - Create human-readable descriptions rather than just numeric vectors\n",
        "2. **Extract Key Intents** - Identify specific user goals beyond surface-level keywords\n",
        "3. **Build Topic Hierarchies** - Create multi-level trees showing relationships between themes\n",
        "\n",
        "### Procedural API Design\n",
        "\n",
        "Kura provides a clean procedural API that makes topic modeling accessible and composable. Rather than complex object hierarchies, you work with simple functions like:\n",
        "\n",
        "- `summarise_conversations()` - Generate LLM summaries of conversations\n",
        "- `generate_base_clusters_from_conversation_summaries()` - Create initial clusters\n",
        "- `reduce_clusters_from_base_clusters()` - Merge similar clusters hierarchically\n",
        "- `reduce_dimensionality_from_clusters()` - Project for visualization\n",
        "\n",
        "This procedural approach makes it easy to customize individual steps, use checkpointing for long-running processes, and build reproducible pipelines while maintaining the flexibility to swap models and configurations.\n",
        "\n",
        "By using LLMs for summarization before clustering, Kura produces more intuitive, actionable results than pure embedding-based approaches, setting the foundation for the systematic RAG improvement framework you'll build across this series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Topic Modeling\n",
        "\n",
        "### What is Topic Modeling?\n",
        "\n",
        "Topic modeling is a technique for automatically discovering themes or patterns in large collections of text. Think of it like sorting a massive pile of documents into folders based on what they're about—except the computer figures out both what the folders should be AND which documents belong in each one.\n",
        "\n",
        "In the context of RAG systems, topic modeling helps us understand what types of questions users are asking without manually reading thousands of queries. Instead of just counting keywords (which misses context), topic modeling identifies semantically related queries that might use completely different words but ask about the same underlying concept.\n",
        "\n",
        "### The Role of Embeddings\n",
        "\n",
        "To group similar texts together, we first need to convert them into a format computers can compare. **Embeddings** are numerical representations of text—think of them as coordinates in a high-dimensional space where similar meanings are positioned closer together.\n",
        "\n",
        "For example:\n",
        "- \"How do I version my model?\" and \"What's the best way to track model versions?\" would have similar embeddings despite using different words\n",
        "- These queries would be far from \"How do I visualize training metrics?\" in the embedding space\n",
        "\n",
        "Modern embedding models (like those used by Kura) capture semantic meaning, not just surface-level word matches. This is why they're so powerful for understanding user intent.\n",
        "\n",
        "### Making Sense with Dimensionality Reduction\n",
        "\n",
        "Embeddings typically have hundreds or thousands of dimensions—impossible to visualize directly. **Dimensionality reduction** techniques compress these high-dimensional representations down to 2D or 3D while preserving the important relationships between points.\n",
        "\n",
        "It's like creating a map of a globe—you lose some information when flattening 3D to 2D, but the relative positions of continents remain meaningful. Similarly, dimensionality reduction lets us visualize which queries cluster together, revealing the natural groupings in our data.\n",
        "\n",
        "In this notebook, Kura handles these technical details for us, but understanding these concepts helps interpret why certain queries group together and how the clustering process works under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding Our Dataset\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "To follow along with this tutorial, you'll need to set up your environment and download the necessary data. For complete setup instructions and to understand how this dataset was created, see the [Getting Started Tutorial](https://0d156a8f.kura-4ma.pages.dev/getting-started/tutorial/).\n",
        "\n",
        "Quick setup:\n",
        "```bash\n",
        "export OPENAI_API_KEY=\"your_api_key\"\n",
        "git clone https://github.com/ivanleomk/kura.git\n",
        "cd kura\n",
        "curl -o conversations.json https://usekura.xyz/data/conversations.json\n",
        "```\n",
        "\n",
        "## Our Dataset\n",
        "\n",
        "We're working with 560 real user queries from the Weights & Biases documentation, each manually labelled with a retrieved relevant document. This dataset gives us direct insight into how users interact with ML experiment tracking documentation.\n",
        "\n",
        "By examining these query-document pairs, we gain valuable insights into:\n",
        "\n",
        "* What information users actively seek and how they phrase questions\n",
        "* Which documentation sections are most needed or confusing\n",
        "* How different query patterns cluster together, revealing common user challenges\n",
        "\n",
        "Topic modeling helps us identify semantically similar conversations, allowing us to group these queries into meaningful clusters that reveal broader patterns of user needs and pain points.\n",
        "\n",
        "For anyone building RAG systems, this kind of dataset is gold. It helps you understand user intent, find gaps in your documentation, and prioritize improvements based on actual usage patterns rather than guesswork.\n",
        "\n",
        "Without systematic analysis of such data, it's nearly impossible to identify patterns in how users interact with your system. Topic modeling gives us a data-driven way to improve retrieval strategies and function calling by understanding the most common user needs.\n",
        "\n",
        "## Preparing Our Data\n",
        "\n",
        "Before using Kura for topic modeling, we need to prepare our dataset. Each entry contains:\n",
        "- `query`: The user's original question\n",
        "- `matching_document`: The relevant document manually matched to this query\n",
        "- `query_id`: Unique identifier for the query\n",
        "- `matching_document_document_id`: ID of the matching document\n",
        "\n",
        "Let's examine what this data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_id': '5e878c76-25c1-4bad-8cae-6a40ca4c8138',\n",
              " 'query': 'experiment tracking',\n",
              " 'matching_document': '## Track Experiments\\n### How it works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics (`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init(entity=\"\", project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n# Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3. Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to W&B\\n\\nwandb.log\\\\_artifact(model)\\n```',\n",
              " 'matching_document_document_id': '1c7f8798-7b2a-4baa-9829-14ada61db6bc',\n",
              " 'query_weight': 0.1}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"./data/conversations.json\") as f:\n",
        "    conversations_raw = json.load(f)\n",
        "\n",
        "conversations_raw[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This raw format isn't immediately useful for topic modeling. We need to transform it into something that Kura can process effectively. \n",
        "\n",
        "To do so, we'll convert it to a `Conversation` class which `Kura` exposes. This format allows Kura to:\n",
        "\n",
        "1. Process the conversation flow (even though we only have single queries in this example)\n",
        "2. Generate summaries of each conversation\n",
        "3. Embed and cluster conversations based on content and structure\n",
        "\n",
        "We'll create a function to convert each query-document pair into a Kura Conversation object with a single user Message that combines both the query and retrieved document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conversation</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92552</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92555</span><span style=\"font-weight: bold\">)</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&amp;B run.\\n2. Store a dictionary </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">(`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&amp;B Experiment tracking </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&amp;B Run\\n\\nwandb.init(entity=\"\", </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3.</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">W&amp;B\\n\\nwandb.log\\\\_artifact(model)\\n```\\n'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversation\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
              "    \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m41\u001b[0m, \u001b[1;36m92552\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m41\u001b[0m, \u001b[1;36m92555\u001b[0m\u001b[1m)\u001b[0m,\n",
              "            \u001b[33mrole\u001b[0m=\u001b[32m'user'\u001b[0m,\n",
              "            \u001b[33mcontent\u001b[0m=\u001b[32m'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it \u001b[0m\n",
              "\u001b[32mworks\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary \u001b[0m\n",
              "\u001b[32mof hyperparameters, such as learning rate or model type, into your configuration \u001b[0m\u001b[32m(\u001b[0m\u001b[32m`wandb.config`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n3. Log metrics \u001b[0m\n",
              "\u001b[32m(\u001b[0m\u001b[32m`wandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model \u001b[0m\n",
              "\u001b[32mweights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking \u001b[0m\n",
              "\u001b[32mworkflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init\u001b[0m\u001b[32m(\u001b[0m\u001b[32mentity\u001b[0m\u001b[32m=\"\", \u001b[0m\n",
              "\u001b[32mproject\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#\u001b[0m\n",
              "\u001b[32mImport model and data\\n\\nmodel, dataloader = get\\\\_model\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, get\\\\_data\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# Model training code goes here\\n\\n# 3.\u001b[0m\n",
              "\u001b[32mLog metrics over time to visualize performance\\n\\nwandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"loss\": loss\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 4. Log an artifact to \u001b[0m\n",
              "\u001b[32mW&B\\n\\nwandb.log\\\\_artifact\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmodel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'query_id'\u001b[0m: \u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import Message, Conversation\n",
        "from datetime import datetime\n",
        "from rich import print\n",
        "\n",
        "def process_query_obj(obj:dict):\n",
        "    return Conversation(\n",
        "    chat_id=obj['query_id'],\n",
        "    created_at=datetime.now(),\n",
        "    messages=[\n",
        "        Message(\n",
        "            created_at=datetime.now(),\n",
        "            role=\"user\",\n",
        "            content=f\"\"\"\n",
        "User Query: {obj['query']}\n",
        "Retrieved Information : {obj['matching_document']}\n",
        "\"\"\"\n",
        "            )\n",
        "        ],\n",
        "        metadata={\n",
        "            'query_id': obj['query_id']\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "print(process_query_obj(conversations_raw[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversations = [process_query_obj(obj) for obj in conversations_raw]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each individual `Conversation` object exposes a metadata field which allows us to provide additional context that can be valuable for analysis.\n",
        "\n",
        "In this case here, we add the Query ID to the metadata field so that we can preserve it for downstream processing. By properly structuring our data and enriching it with metadata, we're setting a strong foundation for the topic modeling work ahead. \n",
        "\n",
        "This careful preparation will pay off when we analyze the results and turn insights into actionable improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Clustering Process\n",
        "\n",
        "Now that we've converted our raw data into Kura's Conversation format, we're ready to run the clustering process. This is where we discover patterns across hundreds of conversations without needing to manually review each one.\n",
        "\n",
        "We'll use Kura's procedural API to group similar conversations together, identify common themes, and build a hierarchical organization of topics. The clustering algorithm combines embedding similarity with LLM-powered summarization to create meaningful, interpretable results.\n",
        "\n",
        "### The Clustering Pipeline\n",
        "\n",
        "The hierarchical clustering process follows a systematic approach using Kura's procedural functions:\n",
        "\n",
        "1. **Summarization**: `summarise_conversations()` - Each conversation is summarized by an LLM to capture its essence while removing sensitive details\n",
        "2. **Embedding**: These summaries are converted into vector embeddings that capture their semantic meaning\n",
        "3. **Base Clustering**: `generate_base_clusters_from_conversation_summaries()` - Similar conversations are grouped into small, initial clusters\n",
        "4. **Hierarchical Merging**: `reduce_clusters_from_base_clusters()` - Similar clusters are progressively combined into broader categories\n",
        "5. **Naming and Description**: Each cluster receives a descriptive name and explanation generated by an LLM\n",
        "6. **Dimensionality Reduction**: `reduce_dimensionality_from_clusters()` - Projects clusters for visualization\n",
        "\n",
        "### Procedural API Benefits\n",
        "\n",
        "Kura's procedural design offers several advantages:\n",
        "\n",
        "- **Composability**: Each function handles one step, making it easy to customize or replace individual components\n",
        "- **Checkpointing**: Save intermediate results to avoid recomputing expensive operations\n",
        "- **Transparency**: Clear function names make the pipeline easy to understand and debug\n",
        "- **Flexibility**: Swap models or configurations without complex object management\n",
        "\n",
        "By starting with many detailed clusters before gradually reducing them to more general topics, we preserve meaningful patterns while making results easy for humans to review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kura import CheckpointManager\n",
        "\n",
        "async def analyze_conversations(conversations, checkpoint_manager):\n",
        "    from kura import (\n",
        "        summarise_conversations, \n",
        "        generate_base_clusters_from_conversation_summaries, \n",
        "        reduce_clusters_from_base_clusters,\n",
        "        reduce_dimensionality_from_clusters\n",
        "    )\n",
        "    from kura.summarisation import SummaryModel\n",
        "    from kura.cluster import ClusterModel\n",
        "    from kura.meta_cluster import MetaClusterModel\n",
        "    from kura.dimensionality import HDBUMAP\n",
        "    \n",
        "    # Set up models\n",
        "    summary_model = SummaryModel()\n",
        "    cluster_model = ClusterModel()\n",
        "    meta_cluster_model = MetaClusterModel()\n",
        "    dimensionality_model = HDBUMAP()\n",
        "    \n",
        "    # Run pipeline steps\n",
        "    summaries = await summarise_conversations(\n",
        "        conversations, \n",
        "        model=summary_model, \n",
        "        checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "    \n",
        "    clusters = await generate_base_clusters_from_conversation_summaries(\n",
        "        summaries, \n",
        "        model=cluster_model, \n",
        "        checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "    \n",
        "    reduced_clusters = await reduce_clusters_from_base_clusters(\n",
        "        clusters, \n",
        "        model=meta_cluster_model, \n",
        "        checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "    \n",
        "    projected = await reduce_dimensionality_from_clusters(\n",
        "        reduced_clusters,   \n",
        "        model=dimensionality_model, \n",
        "        checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "    \n",
        "    return projected\n",
        "\n",
        "\n",
        "checkpoint_manager = CheckpointManager(\"./checkpoints\", enabled=True)\n",
        "checkpoint_manager.save_checkpoint(\"conversations.jsonl\", conversations)\n",
        "clusters = await analyze_conversations(conversations, checkpoint_manager=checkpoint_manager)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the output, we can see the consolidation process happening in real-time. Kura starts with 56 base clusters, then gradually merges them through multiple rounds until we reach 9 final top-level clusters. Each merge combines similar topics while preserving the essential distinctions between different conversation types.\n",
        "\n",
        "Now, let's examine these top-level clusters to understand the main themes in our data. \n",
        "\n",
        "By looking at the cluster names, descriptions, and sizes, we can quickly identify what users are discussing most frequently and how these topics relate to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Optimize security and management for data in AWS</span> : Users sought to improve security by clarifying IAM roles \n",
              "specific to AWS SageMaker training and by exploring best practices for dataset versioning. They also aimed to \n",
              "enhance data storage management strategies while addressing privacy concerns. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Enhance data management and team collaboration</span> : Users requested assistance with data tracking, table manipulation \n",
              "techniques, and improving team collaboration and project management. They sought guidance on collaboration metrics,\n",
              "programming techniques, and best practices for managing project tasks effectively. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Guide on secure API key practices</span> : The user researched different strategies for safely managing API keys, \n",
              "emphasizing best practices in authentication and configuration. Key discussions included the use of environment \n",
              "variables and cloud secrets managers to enhance security measures. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Streamline ML logging and visualization enhancements</span> : Users sought guidance on effectively integrating and \n",
              "utilizing Weights &amp; Biases for machine learning logging and data analysis. They requested best practices for \n",
              "optimizing logging techniques, automating processes, and customizing visualizations to enhance their projects. : \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">178</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Enhance machine learning performance and evaluation</span> : Users sought to improve machine learning models through \n",
              "hyperparameter optimization and logging metrics for accurate evaluations. They requested guidance on tools and \n",
              "libraries to assess model performance effectively. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Guide me on machine learning and Markdown usage</span> : Users received assistance in utilizing Markdown effectively for \n",
              "reports and troubleshooting machine learning tools. They sought guidance on configurations, training runs, and \n",
              "artifact management across various contexts. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Manage and log machine learning experiments efficiently</span> : Users focused on effective management and logging of \n",
              "machine learning experiments. They discussed techniques and specific tools like WandB to optimize performance and \n",
              "tracking. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mOptimize security and management for data in AWS\u001b[0m : Users sought to improve security by clarifying IAM roles \n",
              "specific to AWS SageMaker training and by exploring best practices for dataset versioning. They also aimed to \n",
              "enhance data storage management strategies while addressing privacy concerns. : \u001b[1;36m75\u001b[0m\n",
              "\n",
              "\u001b[1mEnhance data management and team collaboration\u001b[0m : Users requested assistance with data tracking, table manipulation \n",
              "techniques, and improving team collaboration and project management. They sought guidance on collaboration metrics,\n",
              "programming techniques, and best practices for managing project tasks effectively. : \u001b[1;36m67\u001b[0m\n",
              "\n",
              "\u001b[1mGuide on secure API key practices\u001b[0m : The user researched different strategies for safely managing API keys, \n",
              "emphasizing best practices in authentication and configuration. Key discussions included the use of environment \n",
              "variables and cloud secrets managers to enhance security measures. : \u001b[1;36m5\u001b[0m\n",
              "\n",
              "\u001b[1mStreamline ML logging and visualization enhancements\u001b[0m : Users sought guidance on effectively integrating and \n",
              "utilizing Weights & Biases for machine learning logging and data analysis. They requested best practices for \n",
              "optimizing logging techniques, automating processes, and customizing visualizations to enhance their projects. : \n",
              "\u001b[1;36m178\u001b[0m\n",
              "\n",
              "\u001b[1mEnhance machine learning performance and evaluation\u001b[0m : Users sought to improve machine learning models through \n",
              "hyperparameter optimization and logging metrics for accurate evaluations. They requested guidance on tools and \n",
              "libraries to assess model performance effectively. : \u001b[1;36m28\u001b[0m\n",
              "\n",
              "\u001b[1mGuide me on machine learning and Markdown usage\u001b[0m : Users received assistance in utilizing Markdown effectively for \n",
              "reports and troubleshooting machine learning tools. They sought guidance on configurations, training runs, and \n",
              "artifact management across various contexts. : \u001b[1;36m84\u001b[0m\n",
              "\n",
              "\u001b[1mManage and log machine learning experiments efficiently\u001b[0m : Users focused on effective management and logging of \n",
              "machine learning experiments. They discussed techniques and specific tools like WandB to optimize performance and \n",
              "tracking. : \u001b[1;36m123\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get top-level clusters (those without parents)\n",
        "parent_clusters = [cluster for cluster in clusters if cluster.parent_id is None]\n",
        "\n",
        "# Format each cluster's info with name, description and number of chats\n",
        "formatted_clusters = []\n",
        "for cluster in parent_clusters:\n",
        "    cluster_info = (\n",
        "        f\"[bold]{cluster.name}[/bold] : {cluster.description} : {len(cluster.chat_ids)}\"\n",
        "    )\n",
        "    formatted_clusters.append(cluster_info)\n",
        "\n",
        "# Join with newlines and print\n",
        "print(\"\\n\\n\".join(formatted_clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysing Our Results\n",
        "\n",
        "### Understanding Our Top-Level Clusters\n",
        "\n",
        "Looking at the seven top-level clusters generated by Kura, we can identify clear patterns in how users are interacting with the documentation.\n",
        "\n",
        "The three largest clusters account for 69% of all queries:\n",
        "1. **Streamline ML logging and visualization enhancements** (178 conversations) - Users seeking guidance on integrating W&B for logging and customizing visualizations\n",
        "2. **Manage and log machine learning experiments efficiently** (123 conversations) - Focus on experiment management and tracking using tools like WandB\n",
        "3. **Guide me on machine learning and Markdown usage** (84 conversations) - Assistance with Markdown reports and troubleshooting ML tools\n",
        "\n",
        "What's particularly notable is that **logging and experiment management dominate user concerns**. The top two clusters alone represent 54% of all queries (301 out of 560), both focusing on different aspects of experiment tracking and logging.\n",
        "\n",
        "Additional significant themes include:\n",
        "- **AWS integration and security** (75 conversations) - IAM roles, SageMaker training, and data storage\n",
        "- **Team collaboration and data management** (67 conversations) - Table manipulation, collaboration metrics, and project management\n",
        "- **Model performance optimization** (28 conversations) - Hyperparameter tuning and evaluation\n",
        "\n",
        "This clustering reveals that the majority of user questions center around **how to effectively use W&B for logging, tracking, and visualizing ML experiments**. Users are consistently trying to figure out how to properly integrate W&B into their workflows, optimize their logging strategies, and create meaningful visualizations of their results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysing Our Summaries\n",
        "\n",
        "Let's now examine what are some of the summaries that were generated by Kura for our individual query document pairs. \n",
        "\n",
        "To do so, we'll read in the list of conversations that we started with and then find their corresponding summary. This will allows us to then evaluate how representative the conversation summary is of the individual conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user is seeking guidance on tracking machine learning experiments using a specific tool, detailing the steps \n",
              "and providing pseudocode for implementation.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user is seeking guidance on tracking machine learning experiments using a specific tool, detailing the steps \n",
              "and providing pseudocode for implementation.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Create a W&amp;B run.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "<span style=\"font-weight: bold\">(</span>`wandb.config`<span style=\"font-weight: bold\">)</span>.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics <span style=\"font-weight: bold\">(</span>`<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">()</span>`<span style=\"font-weight: bold\">)</span> over time in a training loop, such as accuracy and loss.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&amp;B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Start a W&amp;B Run\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">entity</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"my-project-name\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics over time to visualize performance\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">\"loss\"</span>: loss<span style=\"font-weight: bold\">})</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Log an artifact to W&amp;B\n",
              "\n",
              "wandb.log\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_artifact</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "```\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "\u001b[1;36m1\u001b[0m. Create a W&B run.\n",
              "\u001b[1;36m2\u001b[0m. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "\u001b[1m(\u001b[0m`wandb.config`\u001b[1m)\u001b[0m.\n",
              "\u001b[1;36m3\u001b[0m. Log metrics \u001b[1m(\u001b[0m`\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m`\u001b[1m)\u001b[0m over time in a training loop, such as accuracy and loss.\n",
              "\u001b[1;36m4\u001b[0m. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# \u001b[1;36m1\u001b[0m. Start a W&B Run\n",
              "\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mentity\u001b[0m=\u001b[32m\"\"\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m2\u001b[0m. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = \u001b[1;36m0.01\u001b[0m\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# \u001b[1;36m3\u001b[0m. Log metrics over time to visualize performance\n",
              "\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m\"loss\"\u001b[0m: loss\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m4\u001b[0m. Log an artifact to W&B\n",
              "\n",
              "wandb.log\\\u001b[1;35m_artifact\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "```\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed search, \n",
              "contrasting with grid and random search methods.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed search, \n",
              "contrasting with grid and random search methods.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/fmfn/BayesianOptimization)</span> library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&amp;B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "\u001b[1m(\u001b[0m\u001b[4;94mhttps://github.com/fmfn/BayesianOptimization\u001b[0m\u001b[4;94m)\u001b[0m library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user seeks guidance on integrating a specific tool with a programming framework for tracking machine learning \n",
              "experiments. The conversation includes pseudocode for implementation steps.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user seeks guidance on integrating a specific tool with a programming framework for tracking machine learning \n",
              "experiments. The conversation includes pseudocode for implementation steps.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: How to integrate Weights &amp; Biases with PyTorch?\n",
              "Retrieved Information : ## 🔥 = W&amp;B ➕ PyTorch\n",
              "\n",
              "Use Weights &amp; Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights &amp; Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&amp;B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"new-sota-model\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# capture a dictionary of hyperparameters with config\n",
              "wandb.config = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"learning\\_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"epochs\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"batch\\_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# optional: track gradients\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.watch</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_step</span><span style=\"font-weight: bold\">()</span>\n",
              "# log metrics inside your training loop to visualize model performance\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">(</span>metrics<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_onnx</span><span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.save</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"model.onnx\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: How to integrate Weights & Biases with PyTorch?\n",
              "Retrieved Information : ## 🔥 = W&B ➕ PyTorch\n",
              "\n",
              "Use Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights & Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject\u001b[0m=\u001b[32m\"new\u001b[0m\u001b[32m-sota-model\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# capture a dictionary of hyperparameters with config\n",
              "wandb.config = \u001b[1m{\u001b[0m\u001b[32m\"learning\\_rate\"\u001b[0m: \u001b[1;36m0.001\u001b[0m, \u001b[32m\"epochs\"\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m\"batch\\_size\"\u001b[0m: \u001b[1;36m128\u001b[0m\u001b[1m}\u001b[0m\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: track gradients\n",
              "\u001b[1;35mwandb.watch\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\\u001b[1;35m_step\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "# log metrics inside your training loop to visualize model performance\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0mmetrics\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\\u001b[1;35m_onnx\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1;35mwandb.save\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"model.onnx\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import ConversationSummary\n",
        "\n",
        "checkpoint_manager = CheckpointManager(\"./checkpoints\", enabled=True)\n",
        "summaries = checkpoint_manager.load_checkpoint(\"summaries.jsonl\", ConversationSummary)\n",
        "conversations = checkpoint_manager.load_checkpoint(\"conversations.jsonl\", Conversation)\n",
        "\n",
        "\n",
        "id_to_conversation = {\n",
        "    conversation.chat_id: conversation\n",
        "    for conversation in conversations\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    print(summaries[i].summary)\n",
        "    print(id_to_conversation[summaries[i].chat_id].messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "In this notebook, you discovered how to transform raw user queries into actionable insights for RAG system improvements. You learned to:\n",
        "\n",
        "- **Prepare query data for Kura** by formatting JSON data into Conversation objects with proper metadata\n",
        "- **Run hierarchical clustering** using Kura's built-in capabilities to group similar conversations\n",
        "- **Analyze clustering results** to identify the most common user query patterns and pain points\n",
        "\n",
        "### What We Accomplished\n",
        "\n",
        "By leveraging Kura's clustering capabilities, we organized 560 user queries into nine meaningful clusters that revealed clear patterns in how users interact with Weights & Biases documentation. The analysis showed that three major topics—experiment tracking, tool integration, and artifact management—account for over two-thirds of all queries, with artifact management appearing as a significant theme across multiple clusters (61% of conversations).\n",
        "\n",
        "However, we also identified critical limitations in the default summarization approach. Our generated summaries lacked specificity about the tools users wanted to use and sometimes included irrelevant context from retrieved documents. For example, summaries described queries as \"user seeks information about tracking\" rather than capturing the specific W&B features involved.\n",
        "\n",
        "### Next: Better Summaries\n",
        "\n",
        "While our clustering revealed valuable high-level patterns, the generic summaries limit our ability to understand specific user needs. In the next notebook, \"Better Summaries\", we'll address this limitation by building a custom summarization model that:\n",
        "\n",
        "- **Identifies specific W&B features** (Artifacts, Configs, Reports) mentioned in each query\n",
        "- **Captures precise user intent** rather than generic descriptions  \n",
        "- **Creates domain-specific summaries** tailored to W&B terminology and workflows\n",
        "\n",
        "By replacing vague summaries like \"user seeks information about tracking\" with precise descriptions like \"user is managing W&B Artifacts for model versioning\", we'll create clusters that better reflect real user needs and provide more targeted, actionable insights for system improvements."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
