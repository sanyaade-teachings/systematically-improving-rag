
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Learn how to use your evaluation data to create few-shot examples and training datasets for fine-tuning">
      
      
      
        <link rel="canonical" href="https://567-labs.github.io/systematically-improving-rag/workshops/chapter2/">
      
      
        <link rel="prev" href="../chapter1/">
      
      
        <link rel="next" href="../chapter3-1/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>2. Converting Evaluations into Training Data - Systematically Improving RAG Applications</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config",""),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#converting-evaluations-into-training-data-for-fine-tuning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
  <p>
    This material is supported by <a href="https://maven.com/applied-llms/rag-playbook?promoCode=EBOOK" target="_blank"><strong>Applied LLMs on Maven</strong></a>.  Readers get 20% off.
    Not ready? Check out the <a href="https://fivesixseven.ck.page/rag-crash-course" target="_blank"><strong>free email course</strong></a>.
  </p>

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Systematically Improving RAG Applications" class="md-header__button md-logo" aria-label="Systematically Improving RAG Applications" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Systematically Improving RAG Applications
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2. Converting Evaluations into Training Data
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="black"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  
    
  
  Workshops

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../office-hours/" class="md-tabs__link">
          
  
  
    
  
  Office Hours

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../talks/" class="md-tabs__link">
          
  
  
    
  
  Talks

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Systematically Improving RAG Applications" class="md-nav__button md-logo" aria-label="Systematically Improving RAG Applications" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Systematically Improving RAG Applications
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Workshops
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Workshops
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter0/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 1: Starting the Flywheel
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Chapter 1: Starting the Flywheel
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" checked>
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 2: From Evaluation to Enhancement
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Chapter 2: From Evaluation to Enhancement
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#prerequisites-and-context" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites and context
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Learning objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-generic-embeddings-fall-short" class="md-nav__link">
    <span class="md-ellipsis">
      Why Generic Embeddings Fall Short
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why Generic Embeddings Fall Short">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-elusive-nature-of-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      The Elusive Nature of "Similarity"
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-hidden-assumptions-in-provider-models" class="md-nav__link">
    <span class="md-ellipsis">
      The Hidden Assumptions in Provider Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#from-evaluation-to-few-shot-examples" class="md-nav__link">
    <span class="md-ellipsis">
      From Evaluation to Few-Shot Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="From Evaluation to Few-Shot Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-power-of-examples-in-context" class="md-nav__link">
    <span class="md-ellipsis">
      The Power of Examples in Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selecting-the-right-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Selecting the Right Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#building-your-few-shot-library" class="md-nav__link">
    <span class="md-ellipsis">
      Building Your Few-Shot Library
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implementation-building-the-data-flywheel-for-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implementation: Building the Data Flywheel for Fine-Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Implementation: Building the Data Flywheel for Fine-Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#starting-the-flywheel" class="md-nav__link">
    <span class="md-ellipsis">
      Starting the Flywheel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-data-should-you-log" class="md-nav__link">
    <span class="md-ellipsis">
      What Data Should You Log?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-contrastive-learning-for-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Contrastive Learning for Embeddings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding Contrastive Learning for Embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-through-contrasts" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Through Contrasts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-effective-triplets-for-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Effective Triplets for RAG
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#healthcare-rag-triplet-example" class="md-nav__link">
    <span class="md-ellipsis">
      Healthcare RAG Triplet Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-challenge-of-hard-negatives-and-how-ux-can-help" class="md-nav__link">
    <span class="md-ellipsis">
      The Challenge of Hard Negatives and How UX Can Help
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hard-negative-mining-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Hard Negative Mining Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-power-of-re-rankers-in-rag-systems" class="md-nav__link">
    <span class="md-ellipsis">
      The Power of Re-Rankers in RAG Systems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Power of Re-Rankers in RAG Systems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bi-encoders-vs-cross-encoders-understanding-the-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      Bi-Encoders vs. Cross-Encoders: Understanding the Trade-offs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-training-data-for-re-rankers" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Training Data for Re-Rankers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-fine-tuning-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Fine-Tuning Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Fine-Tuning Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-to-fine-tune-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      When to Fine-Tune Embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-fine-tuning-process" class="md-nav__link">
    <span class="md-ellipsis">
      The Fine-Tuning Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Fine-Tuning Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-data-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Data Preparation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-model-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Model Selection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-training-infrastructure" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Training Infrastructure
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#measuring-success" class="md-nav__link">
    <span class="md-ellipsis">
      Measuring Success
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-pitfalls-to-avoid" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pitfalls to Avoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resources-for-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Resources for Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing-different-approaches-systematically" class="md-nav__link">
    <span class="md-ellipsis">
      Testing Different Approaches Systematically
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-roadmap-for-continuous-improvement" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Roadmap for Continuous Improvement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-adapters-a-cost-effective-alternative" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Adapters: A Cost-Effective Alternative
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Adapters: A Cost-Effective Alternative">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-linear-adapters" class="md-nav__link">
    <span class="md-ellipsis">
      What Are Linear Adapters?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-linear-adapters" class="md-nav__link">
    <span class="md-ellipsis">
      When to Use Linear Adapters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Additional Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Additional Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tools-and-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Tools and Libraries
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tools and Libraries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-embedding-models" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Embedding Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Key Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-learning-in-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Learning In-Depth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaling-and-efficiency-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling and Efficiency Considerations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#success-stories-and-case-studies" class="md-nav__link">
    <span class="md-ellipsis">
      Success Stories and Case Studies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      Reflection Questions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion and Next Steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      What’s next
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-points" class="md-nav__link">
    <span class="md-ellipsis">
      Integration points
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 3: User Experience
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Chapter 3: User Experience
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Design Principles
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Feedback Collection
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3-3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Iterative Improvement
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 4: Topic Modeling
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Chapter 4: Topic Modeling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter4-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter4-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prioritization
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 5: Multimodal Capabilities
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7">
            <span class="md-nav__icon md-icon"></span>
            Chapter 5: Multimodal Capabilities
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter5-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter5-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Implementation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Chapter 6: Architecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            Chapter 6: Architecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter6-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Routing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter6-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tools
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter6-3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Improvement
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../office-hours/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Office Hours
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Office Hours
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/AGENTS/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agents
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 1: Starting the Flywheel
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Chapter 1: Starting the Flywheel
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week1-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-1-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-1-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 2: From Evaluation to Enhancement
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Chapter 2: From Evaluation to Enhancement
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week2-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-2-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-2-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 3: User Experience
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Chapter 3: User Experience
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week3-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-3-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 1
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 4: Topic Modeling
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Chapter 4: Topic Modeling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week4-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-4-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-4-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_8" >
        
          
          <label class="md-nav__link" for="__nav_3_8" id="__nav_3_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 5: Multimodal Capabilities
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_8">
            <span class="md-nav__icon md-icon"></span>
            Chapter 5: Multimodal Capabilities
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week5-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-5-1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort3/week-5-2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 3 - Session 2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 6: Architecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            Chapter 6: Architecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../office-hours/cohort2/week6-summary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cohort 2 - Week 6
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../talks/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Talks
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Talks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Search / Indexing / Chunking
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Search / Indexing / Chunking
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/chromadb-anton-chunking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Text Chunking Strategies (Anton, ChromaDB)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/john-lexical-search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lexical Search in RAG Applications (John Berryman)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/query-routing-anton/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Query Routing for RAG Systems (Anton, ChromaDB)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/semantic-search-exa-will-bryk/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Why Google Search Sucks for AI (Will Bryk, Exa)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/rag-without-apis-browser-michael-struwig/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How OpenBB Ditched APIs and Put RAG in the Browser (Michael Struwig)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Finetuning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            Finetuning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/glean-manav/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Building Custom Embedding Models Per Customer (Manav, Glean)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/fine-tuning-rerankers-embeddings-ayush-lancedb/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    The 12% RAG Performance Boost You're Missing (Ayush, LanceDB)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/embedding-performance-generative-evals-kelly-hong/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Stop Trusting MTEB Rankings (Kelly Hong, Chroma)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Monitoring
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            Monitoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/online-evals-production-monitoring-ben-sidhant/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Why Your AI Is Failing in Production (Ben & Sidhant)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/rag-antipatterns-skylar-payne/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    The RAG Mistakes That Are Killing Your AI (Skylar Payne)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/zapier-vitor-evals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How Zapier 4x'd Their AI Feedback Collection (Vitor)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Coding Agents
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            Coding Agents
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/rag-is-dead-cline-nik/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Why Cline Ditched RAG for Direct Code Reading (Nik Pash)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/colin-rag-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Grep Beat Embeddings on SWE-Bench (Colin Flaherty, Augment)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/sourcegraph-agentic-code-agent-rag/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agentic RAG from first principles (Beyang Liu, Sourcegraph)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/devin-cognition-multi-agents/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Why Devin does not use multi-agents (Walden Yan)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_6" >
        
          
          <label class="md-nav__link" for="__nav_4_6" id="__nav_4_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Document Processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_6">
            <span class="md-nav__icon md-icon"></span>
            Document Processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/reducto-docs-adit/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Why Most Document Parsing Sucks (Adit, Reducto)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/superlinked-encoder-stacking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Encoder Stacking and Multi-Modal Retrieval (Daniel, Superlinked)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../talks/extend-document-automation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    How Extend Achieves 95%+ Document Automation (Eli Badgio)
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#prerequisites-and-context" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites and context
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-objectives" class="md-nav__link">
    <span class="md-ellipsis">
      Learning objectives
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-generic-embeddings-fall-short" class="md-nav__link">
    <span class="md-ellipsis">
      Why Generic Embeddings Fall Short
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Why Generic Embeddings Fall Short">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-elusive-nature-of-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      The Elusive Nature of "Similarity"
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-hidden-assumptions-in-provider-models" class="md-nav__link">
    <span class="md-ellipsis">
      The Hidden Assumptions in Provider Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#from-evaluation-to-few-shot-examples" class="md-nav__link">
    <span class="md-ellipsis">
      From Evaluation to Few-Shot Examples
    </span>
  </a>
  
    <nav class="md-nav" aria-label="From Evaluation to Few-Shot Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-power-of-examples-in-context" class="md-nav__link">
    <span class="md-ellipsis">
      The Power of Examples in Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#selecting-the-right-examples" class="md-nav__link">
    <span class="md-ellipsis">
      Selecting the Right Examples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#building-your-few-shot-library" class="md-nav__link">
    <span class="md-ellipsis">
      Building Your Few-Shot Library
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implementation-building-the-data-flywheel-for-fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implementation: Building the Data Flywheel for Fine-Tuning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Implementation: Building the Data Flywheel for Fine-Tuning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#starting-the-flywheel" class="md-nav__link">
    <span class="md-ellipsis">
      Starting the Flywheel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#what-data-should-you-log" class="md-nav__link">
    <span class="md-ellipsis">
      What Data Should You Log?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-contrastive-learning-for-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Contrastive Learning for Embeddings
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understanding Contrastive Learning for Embeddings">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#learning-through-contrasts" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Through Contrasts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-effective-triplets-for-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Effective Triplets for RAG
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#healthcare-rag-triplet-example" class="md-nav__link">
    <span class="md-ellipsis">
      Healthcare RAG Triplet Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-challenge-of-hard-negatives-and-how-ux-can-help" class="md-nav__link">
    <span class="md-ellipsis">
      The Challenge of Hard Negatives and How UX Can Help
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hard-negative-mining-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Hard Negative Mining Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-power-of-re-rankers-in-rag-systems" class="md-nav__link">
    <span class="md-ellipsis">
      The Power of Re-Rankers in RAG Systems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Power of Re-Rankers in RAG Systems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bi-encoders-vs-cross-encoders-understanding-the-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      Bi-Encoders vs. Cross-Encoders: Understanding the Trade-offs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#creating-training-data-for-re-rankers" class="md-nav__link">
    <span class="md-ellipsis">
      Creating Training Data for Re-Rankers
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-fine-tuning-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Fine-Tuning Workflow
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Fine-Tuning Workflow">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#when-to-fine-tune-embeddings" class="md-nav__link">
    <span class="md-ellipsis">
      When to Fine-Tune Embeddings
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-fine-tuning-process" class="md-nav__link">
    <span class="md-ellipsis">
      The Fine-Tuning Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Fine-Tuning Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-data-preparation" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Data Preparation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-model-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Model Selection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-training-infrastructure" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Training Infrastructure
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#measuring-success" class="md-nav__link">
    <span class="md-ellipsis">
      Measuring Success
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#common-pitfalls-to-avoid" class="md-nav__link">
    <span class="md-ellipsis">
      Common Pitfalls to Avoid
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resources-for-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Resources for Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing-different-approaches-systematically" class="md-nav__link">
    <span class="md-ellipsis">
      Testing Different Approaches Systematically
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#building-a-roadmap-for-continuous-improvement" class="md-nav__link">
    <span class="md-ellipsis">
      Building a Roadmap for Continuous Improvement
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-adapters-a-cost-effective-alternative" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Adapters: A Cost-Effective Alternative
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Adapters: A Cost-Effective Alternative">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-are-linear-adapters" class="md-nav__link">
    <span class="md-ellipsis">
      What Are Linear Adapters?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#when-to-use-linear-adapters" class="md-nav__link">
    <span class="md-ellipsis">
      When to Use Linear Adapters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Additional Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Additional Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tools-and-libraries" class="md-nav__link">
    <span class="md-ellipsis">
      Tools and Libraries
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tools and Libraries">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-embedding-models" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Embedding Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#key-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      Key Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Key Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#contrastive-learning-in-depth" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Learning In-Depth
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scaling-and-efficiency-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Scaling and Efficiency Considerations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#success-stories-and-case-studies" class="md-nav__link">
    <span class="md-ellipsis">
      Success Stories and Case Studies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reflection-questions" class="md-nav__link">
    <span class="md-ellipsis">
      Reflection Questions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion and Next Steps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#whats-next" class="md-nav__link">
    <span class="md-ellipsis">
      What’s next
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-points" class="md-nav__link">
    <span class="md-ellipsis">
      Integration points
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="converting-evaluations-into-training-data-for-fine-tuning">Converting Evaluations into Training Data for Fine-Tuning</h1>
<h2 id="prerequisites-and-context">Prerequisites and context</h2>
<ul>
<li>Read: <a href="../chapter1/">1. Kickstarting the Data Flywheel with Synthetic Data</a></li>
<li>You have evaluation examples and retrieval metrics in place</li>
</ul>
<h2 id="learning-objectives">Learning objectives</h2>
<ul>
<li>Turn eval examples into few-shot prompts</li>
<li>Build datasets with positives and hard negatives</li>
<li>Fine-tune embeddings/re-rankers and measure impact</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Key Insight</p>
</div>
<p><strong>If you're not fine-tuning, you're Blockbuster, not Netflix.</strong> And this is something I've said to a lot of different consulting clients in the past. The goal isn't to fine-tune language models, right? Those are pretty hard and pretty expensive to train and require a lot of expertise. The goal is to train and fine-tune embedding models, ones that move towards your datasets and improve retrieval and not generation.</p>
<div class="admonition success">
<p class="admonition-title">Fine-Tuning Cost Reality Check</p>
</div>
<p><strong>Embedding Model Fine-Tuning:</strong> - Cost: ~$1.50 for 6,000 examples - Time: 40 minutes on a laptop - Infrastructure: Consumer GPU or cloud notebook - Improvement: 6-10% better performance</p>
<div class="highlight"><pre><span></span><code>**Language Model Fine-Tuning:**
- Cost: $100-1000s depending on model size
- Time: Hours to days
- Infrastructure: Multiple GPUs or specialized services
- Complexity: Requires ML expertise

This dramatic difference explains why embedding fine-tuning should be your first focus.
</code></pre></div>
<h2 id="introduction">Introduction</h2>
<p>In the previous chapter, we set up evaluation and generated synthetic data to benchmark our RAG system. Now let's talk about how to actually use that data to improve things.</p>
<p><strong>Prerequisites from Previous Chapters:</strong></p>
<ul>
<li><strong><a href="../chapter0/">Chapter 0</a></strong>: Understanding the improvement flywheel concept</li>
<li><strong><a href="../chapter1/">Chapter 1</a></strong>: Creating evaluation datasets with synthetic data</li>
</ul>
<p>The evaluation examples from Chapter 1 become your training data in this chapter.</p>
<p>Here's the thing: the data you collect for evaluation shouldn't just sit there. Every question, every relevance judgment, every piece of feedback—it can all be used to improve your system. That's what we'll cover here.</p>
<blockquote>
<p><strong>Key Philosophy:</strong> "Every evaluation example is a potential training example. The data flywheel transforms what begins as a handful of evaluation examples into few-shot prompts, then into training datasets for fine-tuning embedding models and re-rankers."</p>
</blockquote>
<p>The process is straightforward: you start with evaluation examples, turn them into few-shot prompts, then eventually use them to fine-tune your embedding models and re-rankers. Each step builds on the last.</p>
<h2 id="why-generic-embeddings-fall-short">Why Generic Embeddings Fall Short</h2>
<p>Let me start with something that trips up a lot of teams: generic embeddings from providers like OpenAI often don't work great for specialized applications. They're good models, don't get me wrong. But they're built to handle everything, which means they don't handle your specific thing particularly well.</p>
<div class="admonition warning">
<p class="admonition-title">Limitation of Generic Models</p>
</div>
<p>Generic embedding models come with built-in assumptions about what "similarity" means. You don't know:</p>
<div class="highlight"><pre><span></span><code>- What data they were trained on
- How they defined &quot;success&quot; during training
- How they weighted different types of similarity
- What trade-offs they made to work for everyone
</code></pre></div>
<h3 id="the-elusive-nature-of-similarity">The Elusive Nature of "Similarity"</h3>
<p>Embedding models seem simple enough: they turn text into numbers, and similar text should end up with similar numbers. Measure the distance between vectors and you know how similar things are.</p>
<p>But here's the big assumption we're making: that the embedding of the query vector should be similar to the embedding of a text chunk that just happens to have the answer. That's a very big assumption, and fundamentally, there's actually no consensus.</p>
<p><strong>Domain-Specific Similarity:</strong> In e-commerce, what makes two products "similar"? Are they substitutes (different brands of red shirts) or complements (a shirt and matching pants)? Depends on what you're trying to do.</p>
<p>I used to do a lot of image-based recommendation systems, so now imagine a query of a red shirt. Is similar mean just more similar red shirts? Does it matter if I'm looking at a silk shirt or does it matter that I'm looking at a $20 polyester shirt? Are shirts more similar if they have different crew necks, but the colors are different, or should we be thinking about pants, shoes, and bags that complement this red shirt as part of an outfit?</p>
<p>All of these could be correct, and all of these could be incorrect, but they fundamentally go back down to the simple idea that the quality of your multimodal embedding depends on the objective function that you use to fit and train these embedding models.</p>
<p>Take music recommendations. Songs might be similar because they're the same genre, or because they show up in the same playlists, or because the same people like them. If you're adding songs to a playlist, you want one kind of similarity. If you're building Spotify's Discovery Weekly, you want something else entirely.</p>
<p>Think about the embedding of a song versus the embedding of a user of Spotify. Is it the probability that the user will listen to the song? Is it the probability that they will add it to their playlist or they'll heart it? Again, not really sure. We can even go further. Imagine the embedding of a song compared to the embedding of another song. Does the distance correlate with whether or not they're in the same playlist or if they're liked by the same people or if they have the same style or the BPM?</p>
<p>We realize that all of what we're doing here is we're assuming what the distance function really tries to correlate with without actually having the ability to train a model that just points at exactly what we care about.</p>
<p>My favorite example is from dating apps. Maybe you're building like a Hinge or a Tinder. Someone's bio says "I love coffee," and someone else's bio says "I hate coffee." Should "I love coffee" or "I hate coffee" be similar or different? From a linguistics perspective, it might be different because they're obviously negations of each other, but maybe they're all just preferences.</p>
<p>Maybe they're different because people who love coffee would not date people who hate coffee. Maybe they're similar because all of this actually specifies that they are foodies. This might demonstrate some strong preferences for foods and drinks and whatnot. And maybe as long as one loves tea and one drinks coffee, they'll actually get along. But again, who really knows?</p>
<p>Here's the thing: <strong>What actually matters for a dating app is whether two people will like each other</strong>, not whether their profiles use similar words. Generic embeddings trained on web text have no idea about this.</p>
<p>But really what's happening is that these questions don't actually matter in isolation. Even if OpenAI Embeddings has data on comparing texts, the objective function is very different based on the product you're building. And ultimately, what we actually care about building in a dating app is whether or not two profiles, when you compare them, predicts whether they will like each other, not that the text is similar.</p>
<p>The problem is that "similarity" means different things in different contexts. There's no universal right answer—it depends on what you're trying to do.</p>
<h3 id="the-hidden-assumptions-in-provider-models">The Hidden Assumptions in Provider Models</h3>
<p>When you use OpenAI or Cohere's embeddings, you're stuck with their definition of similarity. It might not match what you need.</p>
<p>Using a third party provider's embedding model bakes many assumptions on what similarity means. And that definition is baked into the dataset that we use to train it. And if you don't know what it is, and if you don't know what the data set they're using is, you're not going to know what similarity means.</p>
<p>So what does this mean for us, right? We're not actually controlling what a successful match is defined as. And to be aware of the significant gap between the text embeddings and the rankers you use will ultimately determine how we define a successful match.</p>
<p><strong>Legal Document Search Failure:</strong> One memorable case involved a legal document search application. The generic embeddings performed reasonably well for finding factual information but struggled with procedural questions. The embeddings didn't adequately capture the relationships between legal procedures and their applications—a specific type of similarity vital to legal professionals but not emphasized in general-purpose training data.</p>
<p>Maybe you're doing internal documents or maybe you're doing healthcare or legal or tax. Those things aren't immediately obvious. And you can imagine a situation where embedding models can't really figure out the difference between a neither or nor. And now we can put them into the context of a language model and it could confuse the language model.</p>
<p>Provider embeddings aren't bad—they're great for general use. But your application probably isn't general. Fine-tuning with your own data fixes this mismatch.</p>
<h2 id="from-evaluation-to-few-shot-examples">From Evaluation to Few-Shot Examples</h2>
<p>Before jumping into fine-tuning, there's something simpler you can try: few-shot examples. Let's talk about turning your evaluation data into prompts that actually work.</p>
<h3 id="the-power-of-examples-in-context">The Power of Examples in Context</h3>
<p>Few-shot learning is pretty straightforward: instead of retraining the model, you just show it some examples in the prompt. No special infrastructure needed.</p>
<p><strong>How Few-Shot Learning Works:</strong> When you provide a language model with examples of how to respond to similar queries, you activate its ability to recognize patterns and apply them to new inputs. It's like showing a human a few examples of a task before asking them to perform it themselves—no specialized training required, just clear demonstrations.</p>
<p>This works especially well for RAG because different types of questions need different approaches. Show the model a few examples and it figures out what kind of question it's dealing with.</p>
<h3 id="selecting-the-right-examples">Selecting the Right Examples</h3>
<p>Don't just grab random examples from your evaluation set. I've watched teams do this and make their model worse. You need to pick the right examples.</p>
<p><strong>Characteristics of Good Examples:</strong></p>
<ul>
<li>Match the queries your users actually ask</li>
<li>Show clear reasoning steps</li>
<li>Cover different types of questions</li>
<li>Aren't too weird or specific</li>
</ul>
<p>Remember the synthetic data generation techniques we explored in Chapter 1? You can use those same methods to generate examples specifically for few-shot learning. The key difference is that for few-shot examples, you need not just questions and answers, but also the reasoning process that connects them.</p>
<h3 id="building-your-few-shot-library">Building Your Few-Shot Library</h3>
<p>Build yourself a library of few-shot examples. Here's how I do it:</p>
<ol>
<li>Filter your evaluation data for the best examples</li>
<li>Group them by type (factual questions, how-to guides, comparisons)</li>
<li>Pick representative examples from each group</li>
<li>Format them consistently</li>
<li>Test them with your actual pipeline</li>
<li>Keep the ones that work, toss the ones that don't</li>
</ol>
<p><strong>Structured Few-Shot Prompt:</strong></p>
<div class="highlight"><pre><span></span><code>You are an assistant specialized in answering questions about [domain].

Here are some examples of how to answer questions:

Question: [Example Question 1]
Thinking: [First, I&#39;ll identify the key entities in the question. Then I&#39;ll look for information about their relationship...]
Answer: [Example Answer 1]

Question: [Example Question 2]
Thinking: [This appears to be a comparison question. I should look for information about both entities and highlight similarities and differences...]
Answer: [Example Answer 2]

Now please answer the following question:
Question: [Actual User Query]
</code></pre></div>
<p>Having an organized library means you can track what works, swap out examples that get stale, and keep improving based on what your users actually do.</p>
<h2 id="practical-implementation-building-the-data-flywheel-for-fine-tuning">Practical Implementation: Building the Data Flywheel for Fine-Tuning</h2>
<p>Few-shot examples are great, but fine-tuning your embeddings is where you see real improvements. The trick is getting enough good data to make it worth doing.</p>
<h3 id="starting-the-flywheel">Starting the Flywheel</h3>
<p>Building a RAG system is iterative. You start with a few examples for evaluation. Those become few-shot prompts. Eventually you have enough for fine-tuning. Each stage builds on the last.</p>
<p><strong>Data Collection Milestones:</strong></p>
<ul>
<li>With 20 examples, you can build basic evaluation benchmarks</li>
<li>With 30 examples, you can create effective few-shot prompts</li>
<li>With 1000+ examples, you can fine-tune your retrieval models</li>
</ul>
<p>What's nice is you're not throwing away data—you're using it differently as you get more of it.</p>
<div class="admonition warning">
<p class="admonition-title">Start Collecting Now</p>
</div>
<p>You need to start collecting the right data now, even if you're not ready to fine-tune yet. The sooner you start logging relevant user interactions, the sooner you'll reach the critical mass needed for fine-tuning.</p>
<h3 id="what-data-should-you-log">What Data Should You Log?</h3>
<p>For RAG, here's what you should be logging:</p>
<ol>
<li>What users actually ask</li>
<li>Which chunks got used in responses</li>
<li>Which responses users liked (or didn't)</li>
<li>Which queries needed follow-ups</li>
</ol>
<p>This tells you what's actually relevant to what—which is exactly what you need for fine-tuning.</p>
<p><strong>Domain-Specific Relevance Signals:</strong></p>
<p>For other applications, the relevance signals will differ:</p>
<ul>
<li>In e-commerce: track which items are purchased together, viewed in sequence, or added to the same lists</li>
<li>For music recommendations: log which songs appear in the same playlists or are hearted by the same users</li>
<li>For dating apps: record which profiles match and go on to have meaningful conversations</li>
</ul>
<p>The key is defining what "relevance" means in your specific context and systematically collecting data that captures this relationship.</p>
<div class="admonition warning">
<p class="admonition-title">Start Logging Yesterday!</p>
</div>
<p>I've seen numerous companies hire machine learning engineers to fine-tune embedding models, only to realize they hadn't started logging relevance data. These teams then have to wait 3-6 months to collect enough data before they can begin the work they intended to do immediately.</p>
<div class="highlight"><pre><span></span><code>**The most important action you can take today is to start logging relevance data**, even if you&#39;re not ready to hire ML specialists or begin fine-tuning. Save the top 20-40 chunks for each query and use an LLM to mark relevance if human annotation isn&#39;t feasible. This data will be invaluable when you&#39;re ready to improve your models.
</code></pre></div>
<p>I watched a team build a great RAG app for internal docs. Six months later they wanted to fine-tune embeddings but had zero data because they never set up logging. Had to start from scratch with synthetic data. Don't do this.</p>
<p><strong>Small Datasets Can Make Big Differences:</strong> The team at Sentence Transformers has demonstrated that even with just 6,000 examples, you can achieve 6-10% better performance. With 40 minutes of fine-tuning on a laptop, you can create significant lifetime value for your application. This makes fine-tuning embedding models accessible even to teams without massive datasets or specialized infrastructure.</p>
<p>And honestly, everything that we're doing today with language models is what I used to have to pay data labeling teams hundreds of thousands of dollars to do every year. This is effectively what the machine learning playbook used to be like, but it was only accessible at large companies who could pay hundreds of thousands of dollars. And now what used to be completely inaccessible for small teams can be done just with a couple of prompts with a policy and a for loop.</p>
<p>So I really wanted to think of seizing the opportunity and getting these very big wins in recall, six, 10, 20 percent improvements in recall, but just spending probably a couple hundred dollars of API calls.</p>
<h2 id="understanding-contrastive-learning-for-embeddings">Understanding Contrastive Learning for Embeddings</h2>
<p>Let's talk about how fine-tuning actually works. Most approaches use something called contrastive learning.</p>
<h3 id="learning-through-contrasts">Learning Through Contrasts</h3>
<p>Contrastive learning is simple: you teach the model what's similar by showing it what's different. It's all about relationships, not absolute values.</p>
<p>Ideally when we're fine-tuning examples, we can create these things called triplets. And what we're trying to learn is that for the negative examples, the things that are not relevant, we're learning to push them apart. And when we know something is relevant, we're trying to bring things together.</p>
<p><strong>Triplet Structure:</strong>
The most common implementation uses a structure called a triplet, which consists of:</p>
<ol>
<li>An <strong>anchor</strong> (usually the query)</li>
<li>A <strong>positive example</strong> (a document that's relevant to the query)</li>
<li>A <strong>negative example</strong> (a document that's not relevant to the query)</li>
</ol>
<p>The goal of training is straightforward: adjust the embedding model so that the distance between the anchor and positive example decreases, while the distance between the anchor and negative example increases. In other words, pull similar things closer together and push dissimilar things further apart.</p>
<div class="highlight"><pre><span></span><code>graph LR
    A[Anchor: Query] --- P[Positive: Relevant Document]
    A --- N[Negative: Irrelevant Document]
    P -.- |&quot;Pull Closer&quot;| A
    N -.- |&quot;Push Away&quot;| A
</code></pre></div>
<p>This works great for embeddings because you're directly optimizing the distance relationships that matter for retrieval.</p>
<p>So what happens when we start fine-tuning? If you look at the image on the left, what is before fine-tuning, there are some examples that are negative or irrelevant, and there might be closer to the anchor. In this case, this would be like the embedding of the query vector. And then we might have data that is relevant, but might be farther away. This is the thing that's on position 20, and after we fine-tune, what we can try to get them all to do is move relevant examples closer to the vector and move negative examples further away from the vector.</p>
<h3 id="creating-effective-triplets-for-rag">Creating Effective Triplets for RAG</h3>
<p>For RAG applications, there are several natural ways to create triplet datasets:</p>
<ul>
<li><strong>Anchor</strong>: The user's query</li>
<li><strong>Positive</strong>: Document chunks that were cited in the final response or received positive feedback</li>
<li><strong>Negative</strong>: Document chunks that were retrieved but not cited, or received negative feedback</li>
</ul>
<p>For example, you could say the positive examples are the texts that we included in the context and we cited. And the negative examples might be documents in the context that we didn't cite. This would be a very aggressive form of defining some of these things.</p>
<h3 id="healthcare-rag-triplet-example">Healthcare RAG Triplet Example</h3>
<p>Imagine a healthcare RAG application where a user asks:</p>
<div class="highlight"><pre><span></span><code>```
What are the side effects of medication X?
```

Our retrieval system might return several documents, including:

```
Document A: &quot;Medication X may cause drowsiness, nausea, and in rare cases, allergic reactions.&quot;

Document B: &quot;Medication X is used to treat high blood pressure and should be taken with food.&quot;
```

If Document A is cited in the response while Document B isn&#39;t, we can create a triplet:

```json
{
  &quot;anchor&quot;: &quot;What are the side effects of medication X?&quot;,
  &quot;positive&quot;: &quot;Medication X may cause drowsiness, nausea, and in rare cases, allergic reactions.&quot;,
  &quot;negative&quot;: &quot;Medication X is used to treat high blood pressure and should be taken with food.&quot;
}
```
</code></pre></div>
<p>Through many such examples, the model learns that queries about side effects should be closer to texts describing adverse reactions than to texts describing indications or administration instructions.</p>
<h3 id="the-challenge-of-hard-negatives-and-how-ux-can-help">The Challenge of Hard Negatives and How UX Can Help</h3>
<p>Notice something subtle in that example? The negative document is still about the same medication—just not about side effects. That's a "hard negative": similar in some ways, different in the ways that matter.</p>
<h3 id="hard-negative-mining-strategies">Hard Negative Mining Strategies</h3>
<p><strong>Effective Approaches:</strong></p>
<ol>
<li>
<p><strong>Semantic Similarity with Different Intent:</strong></p>
</li>
<li>
<p>"Software engineer" vs "Software engineering recruiter"</p>
</li>
<li>
<p>Both about software roles, but serving different user needs</p>
</li>
<li>
<p><strong>User Deletion Signals:</strong></p>
</li>
<li>
<p>Track which documents users actively remove from results</p>
</li>
<li>
<p>These are perfect hard negatives - retrieved but explicitly rejected</p>
</li>
<li>
<p><strong>Category Boundaries:</strong></p>
</li>
<li>
<p>Items from adjacent but different categories</p>
</li>
<li>
<p>Example: "Red running shoes" vs "Red dress shoes"</p>
</li>
<li>
<p><strong>Temporal Relevance:</strong></p>
</li>
<li>Outdated versions of correct information</li>
<li>Example: "2023 tax rates" when user needs "2024 tax rates"</li>
</ol>
<blockquote>
<p><strong>Agentic Retrieval Perspective:</strong> Colin Flaherty's work on agentic coding systems reveals a surprising insight: "We found that for SweeBench tasks, embedding-based retrieval was not the bottleneck - grep and find were sufficient." The agent's persistence effectively compensated for less sophisticated tools. This suggests that while fine-tuning embeddings is valuable, the agent layer can sometimes overcome retrieval limitations through persistence. <a href="../../talks/colin-rag-agents/">Learn more about agentic approaches →</a></p>
</blockquote>
<p><strong>Value of Hard Negatives:</strong> Hard negatives are way more valuable than easy ones. If your negative example was about car maintenance instead of medications, the model learns nothing—it already knows car maintenance isn't relevant to medication side effects.</p>
<p>The real challenge is teaching the model to distinguish between different aspects of the same topic. That's where you get actual improvements.</p>
<p>That's why hard negative mining matters—finding examples that are tricky but teachable.</p>
<p><strong>Designing UX for Better Training Data</strong></p>
<p>If you're serious about improving your embeddings, consider explicitly designing your UX to capture these signals:</p>
<ol>
<li>
<p><strong>Document-level feedback mechanisms</strong>: Add simple thumbs up/down options next to each retrieved document, not just for the final answer</p>
</li>
<li>
<p><strong>Click tracking</strong>: Record which documents users click on and which they ignore—those ignored despite ranking highly are excellent hard negative candidates</p>
</li>
<li>
<p><strong>Dwell time analysis</strong>: If a user quickly returns from a document without spending time reading it, that's a strong signal it wasn't relevant</p>
</li>
<li>
<p><strong>Explicit comparison interfaces</strong>: For critical applications, consider interfaces that ask users to compare documents and select the most relevant one</p>
</li>
<li>
<p><strong>Query reformulation tracking</strong>: When a user modifies their query slightly and gets better results, you can pair the original query with documents from the improved results to create training pairs</p>
</li>
</ol>
<p>One team I worked with added a "more like this" button next to helpful documents. Users loved it, and it gave us perfect training data about what users actually consider similar—which often wasn't what we expected from just reading the text.</p>
<h2 id="the-power-of-re-rankers-in-rag-systems">The Power of Re-Rankers in RAG Systems</h2>
<p>Embeddings do the heavy lifting in retrieval, but re-rankers add polish. The difference: embeddings process queries and documents separately, while re-rankers look at them together and can make smarter decisions.</p>
<h3 id="bi-encoders-vs-cross-encoders-understanding-the-trade-offs">Bi-Encoders vs. Cross-Encoders: Understanding the Trade-offs</h3>
<p>Here's the trade-off: embeddings are fast, re-rankers are accurate.</p>
<p><strong>Model Comparison:</strong></p>
<p><strong>Bi-encoders (embedding models)</strong>:</p>
<ul>
<li>Encode query and document independently</li>
<li>Allow pre-computation of document embeddings</li>
<li>Enable fast vector similarity operations</li>
<li>Work well for first-pass retrieval of candidates</li>
<li>Examples include OpenAI's text-embedding models, SBERT, MPNet</li>
</ul>
<p><strong>Cross-encoders (re-rankers)</strong>:</p>
<ul>
<li>Process query and document together as a pair</li>
<li>Cannot pre-compute relevance scores</li>
<li>Provide more accurate relevance judgments</li>
<li>Work best for re-ranking a smaller set of candidates</li>
<li>Examples include Cohere Rerank, monoT5</li>
</ul>
<p>Use them together: embeddings grab candidates quickly, re-ranker sorts them properly.</p>
<p>Generally you need both. You'll always need the bi-encoder models and you'll always need the cross-encoder models. And again, with a lot of these cases, the data that you generate from your product will be the most important. It is not the model itself. And so your job is just to try the same data set across multiple models that you find on the leaderboards and just figure out which one has the best for your use case.</p>
<p>And what I'll probably say right now is that Cohere's re-ranking API is probably the best that you can use right now. It is very easy to fine-tune and serve data sets.</p>
<p><strong>Re-Ranker Success Story:</strong> One team I worked with was debating whether to invest in fine-tuning their embeddings or implementing a re-ranker. When they tested both approaches, they found that fine-tuning embeddings improved recall from 65% to 78%, while adding a re-ranker (even without fine-tuning) improved it to 82%. Combining both approaches pushed performance to 91%—a transformative improvement from where they started.</p>
<p>I have yet to see an application where adding a re-ranker has not been worth it for the additional latency. Usually I see about 10 percent improvement in recall for maybe a 300 to 500 millisecond additional bump in latency.</p>
<h3 id="creating-training-data-for-re-rankers">Creating Training Data for Re-Rankers</h3>
<p>Re-rankers work better with graded relevance scores instead of just yes/no labels. Try this:</p>
<ol>
<li>Score query-document pairs on a scale (like 0-5)</li>
<li>Include the full range of scores</li>
<li>Train the model to predict these scores</li>
</ol>
<p><strong>Graded Relevance Example:</strong></p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;query&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;How do I reset my password?&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;documents&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Step-by-step password reset guide&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;General account management information&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Creating a strong password&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;About our company&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;score&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div>
<p>This helps the re-ranker understand degrees of relevance, not just binary yes/no. Users notice the difference.</p>
<h2 id="practical-fine-tuning-workflow">Practical Fine-Tuning Workflow</h2>
<p>Here's a workflow that actually works, based on what I've seen teams do successfully.</p>
<h3 id="when-to-fine-tune-embeddings">When to Fine-Tune Embeddings</h3>
<p>Fine-tune your embedding models when:</p>
<ol>
<li><strong>You have 6,000+ query-document pairs</strong> with relevance labels</li>
<li><strong>Domain-specific terminology</strong> isn't well-represented in generic models</li>
<li><strong>Your definition of similarity</strong> differs from general language understanding</li>
<li><strong>Cost at scale</strong> justifies maintaining your own infrastructure</li>
</ol>
<p><strong>Production Insight:</strong> You don't need that much data to get started. If you look at these fine-tune examples, the dotted line is the performance of the OpenAI embedding models. And that for something like MP net base V2, even a hundred examples perform better for some of the bigger models, like BGE base 1.5, even at about 500 examples, you start performing better and at a hundred thousand examples, a lot better.</p>
<p>In this case, you'll see that for this model is much easier to train, whereas the Gina embeddings was much harder to train. And we couldn't get a model that actually outperformed OpenAI.</p>
<p>With just 6,000 examples from your domain, you can train embedding models and cross-encoders that outperform general-purpose models on your specific tasks. This typically costs around $1.50 and takes about 40 minutes on a laptop.</p>
<h3 id="the-fine-tuning-process">The Fine-Tuning Process</h3>
<h4 id="step-1-data-preparation">Step 1: Data Preparation</h4>
<p>Transform your evaluation data into training format:</p>
<ul>
<li><strong>Positive pairs</strong>: Query-document combinations that should rank highly</li>
<li><strong>Hard negatives</strong>: Similar but incorrect documents for each query</li>
<li><strong>Validation set</strong>: Hold out 20% for testing improvements</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Critical Success Factor</p>
</div>
<p>The quality of your hard negatives determines the quality of your fine-tuned model. Documents that are topically similar but serve different intents make the best hard negatives.</p>
<h4 id="step-2-model-selection">Step 2: Model Selection</h4>
<p>Choose your base model wisely:</p>
<ul>
<li><strong>For English-only</strong>: Modern BERT models with 8,000 token context (vs original 512)</li>
<li><strong>For multilingual</strong>: Cohere's multilingual models or mE5</li>
<li><strong>For specialized domains</strong>: Start with models pre-trained on similar content</li>
</ul>
<h4 id="step-3-training-infrastructure">Step 3: Training Infrastructure</h4>
<p>You don't need massive infrastructure:</p>
<ul>
<li><strong>Local training</strong>: Consumer GPU with 8GB+ VRAM</li>
<li><strong>Cloud notebooks</strong>: Colab Pro or similar services</li>
<li><strong>Training time</strong>: 30-60 minutes for most datasets</li>
<li><strong>Cost</strong>: Under $5 for most use cases</li>
</ul>
<h3 id="measuring-success">Measuring Success</h3>
<p>Track these metrics before and after fine-tuning:</p>
<ol>
<li><strong>Recall@K</strong> at different values (5, 10, 20)</li>
<li><strong>Mean Reciprocal Rank (MRR)</strong></li>
<li><strong>Business metrics</strong> tied to retrieval quality</li>
<li><strong>Latency impact</strong> if self-hosting</li>
</ol>
<p><strong>Real-World Results:</strong> A healthcare company fine-tuned embeddings on medical abbreviations where generic models confused similar acronyms. Results:</p>
<ul>
<li>Recall@10 improved from 72% to 89%</li>
<li>Reduced confusion between similar medical terms</li>
<li>Cost: $1.50 in compute, 45 minutes of training</li>
<li>ROI: Prevented multiple medical documentation errors</li>
</ul>
<h3 id="common-pitfalls-to-avoid">Common Pitfalls to Avoid</h3>
<ol>
<li><strong>Training on too little data</strong>: Wait until you have at least 6,000 examples</li>
<li><strong>Ignoring hard negatives</strong>: Easy negatives don't improve the model</li>
<li><strong>Not validating on real queries</strong>: Synthetic data alone isn't sufficient</li>
<li><strong>Over-optimizing on metrics</strong>: Ensure improvements translate to user experience</li>
<li><strong>Training too many specific models</strong>: We don't need to train these models to be too task specific. Imagine a world where we have embeddings for questions and table summaries, questions for text chunks, and questions for document summaries. I generally don't recommend training multiple models. Instead, these can all be blended into a single training data set to train a single model, and we can use this to eventually replace the OpenAI embeddings.</li>
<li><strong>Not considering existing embeddings</strong>: If you already have a lot of data embedded, it might not be worth fine-tuning an embedding model because you would have to reapply new embeddings on your vector database. In which case, I would just start thinking about retrieving more chunks and then passing them into something like Cohere's re-ranker models.</li>
</ol>
<h3 id="resources-for-implementation">Resources for Implementation</h3>
<p>For detailed implementation guides:</p>
<ul>
<li><a href="https://www.sbert.net/docs/training/overview.html">Sentence Transformers Training Documentation</a></li>
<li><a href="https://docs.cohere.com/docs/fine-tuning">Cohere's Fine-tuning Guide</a></li>
<li><a href="https://platform.openai.com/docs/guides/fine-tuning">OpenAI's Fine-tuning Best Practices</a></li>
</ul>
<p>If you want to learn more about how we can <a href="https://modal.com/blog/fine-tuning-embeddings">fine-tune models</a> or embed models or host models, take a look at some of our articles. In one, we <a href="https://modal.com/blog/embedding-wikipedia">embedded all of Wikipedia</a> in 15 minutes. And this is just because Modal has allowed us to do very massive parallelization. This way, if I have 10 or 15 different embedding models and I want to know which one works best, instead of running it for nine hours, each one could take 15 minutes and the iteration speed of massive parallelization for embeddings will allow you to have very short turnaround times. And so drastically lower the cost to run any one experiment.</p>
<p>And this parallelization also works for training models. When you train models, there's going to be a ton of different parameters. What's the learning rate? What does this variable look like? What does that variable look like? With something like Modal labs, you can effectively just say, I want to allocate 50 GPUs for 20 minutes, and I want to train 200 different models. I'll pick the one that works the best. And that's how a lot of model training is done.</p>
<blockquote>
<p><strong>Key Takeaway:</strong> "It's probably a bad idea to train your own language model, but it's a very good idea to train your own embedding model. The infrastructure requirements are minimal, the process is well-understood, and the improvements are substantial for domain-specific applications."</p>
</blockquote>
<h2 id="testing-different-approaches-systematically">Testing Different Approaches Systematically</h2>
<p>Now that you have evaluation data from Chapter 1, you can start testing different approaches. You need to be systematic about this.</p>
<p><strong>Good Experimentation Practices:</strong></p>
<p>For each experiment:</p>
<ol>
<li>Have a clear hypothesis ("Re-ranker will improve recall@10 by 15%")</li>
<li>Define success before you start</li>
<li>Change one thing at a time</li>
<li>Measure using your established metrics</li>
<li>Document what worked AND what didn't</li>
</ol>
<p>Experiments worth trying:</p>
<ol>
<li>Different embedding models (OpenAI vs Cohere vs open-source)</li>
<li>Chunk sizes and overlaps</li>
<li>Lexical vs semantic vs hybrid retrieval</li>
<li>Adding a re-ranker</li>
<li>Different few-shot examples</li>
</ol>
<p><strong>Debate Resolved Through Data:</strong> One team I worked with spent weeks debating which embedding model to use, with different team members advocating for their preferred option. Instead of continuing the debate, they implemented a simple experiment: they indexed their documents with three different embedding models and measured recall on their evaluation set. The results settled the debate in hours, not weeks, and the team moved forward with data-backed confidence.</p>
<p>Keep running experiments, measuring results, and iterating. That's how you get better.</p>
<h2 id="building-a-roadmap-for-continuous-improvement">Building a Roadmap for Continuous Improvement</h2>
<p>Once you've run some experiments, you can plan what to do next. It's not just about adding features—it's about having a process.</p>
<p><strong>Prioritization Framework:</strong></p>
<p>When deciding what to work on:</p>
<ul>
<li><strong>Impact</strong>: What will move the needle most?</li>
<li><strong>Effort</strong>: How much work is it?</li>
<li><strong>Dependencies</strong>: What needs to be done first?</li>
<li><strong>Risk</strong>: What could break?</li>
</ul>
<p>I like using a simple impact/effort grid. High impact, low effort goes first—those quick wins build momentum while you're working on the harder stuff.</p>
<p><strong>Prioritization in Action:</strong> In one project, we identified that implementing BM25 hybrid retrieval would be high-impact and medium-effort, while fine-tuning custom embeddings would be high-impact but high-effort. We prioritized the hybrid retrieval first, which gave us immediate gains while we collected data for the eventual embedding fine-tuning.</p>
<h2 id="linear-adapters-a-cost-effective-alternative">Linear Adapters: A Cost-Effective Alternative</h2>
<p>Before diving into full fine-tuning, consider linear adapters - a technique that can deliver significant improvements at a fraction of the cost.</p>
<h3 id="what-are-linear-adapters">What Are Linear Adapters?</h3>
<p>Linear adapters add a small trainable layer on top of frozen embeddings:</p>
<ul>
<li>Train only a linear transformation matrix</li>
<li>Keep the base embedding model unchanged</li>
<li>Combine benefits of domain specificity with pre-trained knowledge</li>
</ul>
<p><strong>Cost Comparison:</strong></p>
<ul>
<li>Full fine-tuning: $50-100 for meaningful datasets</li>
<li>Linear adapters: ~$12 for the same improvement</li>
<li>Training time: Minutes vs hours</li>
</ul>
<h3 id="when-to-use-linear-adapters">When to Use Linear Adapters</h3>
<p><strong>Perfect for:</strong></p>
<ul>
<li>Domain-specific terminology mapping</li>
<li>Multi-domain applications (train separate adapters)</li>
<li>Rapid experimentation</li>
<li>Limited computational resources</li>
</ul>
<p><strong>Implementation:</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># Simplified example</span>
<span class="n">base_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="n">adapted_embeddings</span> <span class="o">=</span> <span class="n">linear_adapter</span><span class="p">(</span><span class="n">base_embeddings</span><span class="p">)</span>
</code></pre></div>
<p>You can train different adapters for different query types or domains, switching between them based on query classification.</p>
<h2 id="additional-resources">Additional Resources</h2>
<h3 id="tools-and-libraries">Tools and Libraries</h3>
<h4 id="understanding-embedding-models">Understanding Embedding Models</h4>
<ol>
<li>
<p><strong>Sentence Transformers Library</strong> (<a href="https://www.sbert.net/">https://www.sbert.net/</a>): This library provides easy-to-use implementations for state-of-the-art embedding models, supporting both pairwise datasets and triplets for fine-tuning. It's my recommended starting point for most teams due to its balance of performance and ease of use.</p>
</li>
<li>
<p><strong>Modern BERT</strong> (<a href="https://huggingface.co/sentence-transformers">https://huggingface.co/sentence-transformers</a>): These newer models offer 8,000 token sequence lengths and generally outperform classic BERT-based models. The BGE models in particular have shown excellent performance across many domains and are worth testing in your applications.</p>
</li>
<li>
<p><strong>Cohere Re-ranking Models</strong> (<a href="https://cohere.com/rerank">https://cohere.com/rerank</a>): Cohere offers state-of-the-art re-ranking capabilities with a fine-tuning API that makes it relatively easy to customize for your specific needs. In my experience, even their base re-ranker without fine-tuning often provides substantial improvements to retrieval quality.</p>
</li>
<li>
<p><strong>Specialized Domains</strong>: For specific domains like code, science, or legal documents, look for models pre-trained on related corpora. For example, CodeBERT for programming or SciBERT for scientific literature can provide better starting points than general models.</p>
</li>
<li>
<p><strong>Comparison to Data Labeling</strong>: Everything we're doing today with fine-tuning embedding models is what I used to pay data labeling teams hundreds of thousands of dollars to do annually. The ML playbook that was once only accessible to large companies with significant budgets is now available to teams of all sizes thanks to advances in transfer learning and fine-tuning techniques.</p>
</li>
</ol>
<p>A long time ago, you would have to build a product with no AI just to collect data. Then we would take that data, then use that to train a model in order to release a product with AI. Now we get a product for free, but many of us are forgetting to collect data in order to improve the systems that we had before.</p>
<p>So it's pretty hard to go from 99 percent to 99.9%, but many of the systems I'm looking at today are at 70%. And the effort it takes to go from 70 to 85 to 90 isn't that big. It might only cost a couple thousand dollars of API calls. Before it would cost tens of thousands of data labeling efforts. But without having to train humans, LLMs allow us to create this label dataset backwards. This is a game changer.</p>
<h3 id="key-concepts">Key Concepts</h3>
<h4 id="contrastive-learning-in-depth">Contrastive Learning In-Depth</h4>
<p>Contrastive learning trains models to recognize similarities and differences between items by pushing and pulling examples in the embedding space:</p>
<ul>
<li><strong>Triplet Loss</strong>: Optimizes the distance between anchor-positive pairs relative to anchor-negative pairs</li>
<li><strong>InfoNCE Loss</strong>: Contrasts a positive pair against multiple negative examples</li>
<li><strong>Multiple Negatives Ranking Loss</strong>: Handles batches of queries with multiple negatives per query</li>
</ul>
<h4 id="scaling-and-efficiency-considerations">Scaling and Efficiency Considerations</h4>
<p>For large datasets or production workloads:</p>
<ul>
<li>Consider parallel processing frameworks (like Modal) to accelerate embedding and training</li>
<li>Experiment with multi-GPU training for faster iterations</li>
<li>Evaluate the trade-offs between API costs and self-hosting</li>
<li>Test multiple model variations simultaneously to find optimal configurations</li>
</ul>
<h4 id="success-stories-and-case-studies">Success Stories and Case Studies</h4>
<p>From other researchers and companies:</p>
<ul>
<li>We've seen a 14 percent accuracy boost over baseline retrieval just by fine-tuning cross-encoders</li>
<li>We can find a 12 percent increase in exact match by mapping to, by training better passage encoders (bi-encoders)</li>
<li>For a lot of companies, we can find a 20 percent improvement in response accuracy just by using re-rankers</li>
<li>Even a 30 percent reduction in irrelevant documents. And irrelevant documents will also make your answers worse depending on what kind of model you use</li>
</ul>
<h2 id="reflection-questions">Reflection Questions</h2>
<ol>
<li>
<p>What specific definition of "similarity" is most important for your application's domain?</p>
</li>
<li>
<p>How would you create effective few-shot examples from your existing evaluation data?</p>
</li>
<li>
<p>What user interactions in your application could provide valuable training signals for fine-tuning?</p>
</li>
<li>
<p>If you had to prioritize one retrieval improvement for your system, would it be embeddings, re-ranking, or something else? Why?</p>
</li>
<li>
<p>What experiments could you run to test your hypotheses about improving retrieval quality?</p>
</li>
</ol>
<h2 id="conclusion-and-next-steps">Conclusion and Next Steps</h2>
<p>We covered a lot:</p>
<ol>
<li>Turning evaluation examples into few-shot prompts</li>
<li>Why generic embeddings often aren't good enough</li>
<li>Building datasets for fine-tuning</li>
<li>How contrastive learning works</li>
<li>Running systematic experiments</li>
<li>Planning improvements</li>
</ol>
<p>The main takeaway: don't waste your data. Every question, every bit of feedback, every evaluation—it can all make your system better if you capture and use it.</p>
<p>Fine-tuning embeddings really works, and unlike fine-tuning LLMs, it's actually doable. You can see real improvements with just 6,000 examples.</p>
<p>And this practice of using synthetic data to create evals, to create fine-tuning datasets, to create few-shot examples. This is the wax on wax off moment. We're going to take the synthetic data, we're going to work on logging, and when we have 20 examples, they become evals. If we have 30 examples, they become few shots. And if we have a thousand examples, now we can start fine-tuning. And this pattern is going to just happen over and over again. It's never going to be done, it's just going to be better.</p>
<h2 id="whats-next">What’s next</h2>
<p>Continue to <a href="../chapter3-1/">3.1 Feedback Collection</a></p>
<h2 id="integration-points">Integration points</h2>
<ul>
<li><strong>Query segmentation</strong> (<a href="../chapter4-1/">4.1</a>, <a href="../chapter4-2/">4.2</a>): Identify which segments benefit most from fine-tuning</li>
<li><strong>Specialized retrievers</strong> (<a href="../chapter5-1/">5.1</a>): Use tuned embeddings to power purpose-built indices</li>
<li><strong>Router optimization</strong> (<a href="../chapter6-2/">6.2</a>): Improve routing with clearer similarity definitions</li>
</ul>
<h2 id="summary">Summary</h2>
<p>Start with evaluation, add few-shot examples, work up to fine-tuning. Each step makes the next one better.</p>
<p>Do these things now:</p>
<ol>
<li><strong>Start logging data</strong> - Even if you're not ready to use it</li>
<li><strong>Define what "similar" means for you</strong> - It's different for every application</li>
<li><strong>Add feedback mechanisms</strong> - You'll need the data later</li>
<li><strong>Build your few-shot library</strong> - Start small, grow over time</li>
<li><strong>Try domain-specific models</strong> - They might already solve your problem</li>
</ol>
<p>If you do this right, every piece of data makes your system better. The improvements compound over time and affect everything—clustering, topic modeling, all of it.</p>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../chapter1/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Overview">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Overview
              </div>
            </div>
          </a>
        
        
          
          <a href="../chapter3-1/" class="md-footer__link md-footer__link--next" aria-label="Next: Design Principles">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Design Principles
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://x.com/jxnlco" target="_blank" rel="noopener" title="x.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "navigation.instant", "navigation.tracking", "navigation.expand", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.footer", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
    
  </body>
</html>